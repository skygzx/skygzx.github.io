<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">

<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>


<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/mand.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/mand.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/mand.jpg?v=5.1.4">






  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="skygzx" type="application/atom+xml">






<meta name="description" content="记录skygzx的学习历程">
<meta property="og:type" content="website">
<meta property="og:title" content="skygzx">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="skygzx">
<meta property="og:description" content="记录skygzx的学习历程">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="skygzx">
<meta name="twitter:description" content="记录skygzx的学习历程">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/">





  <title>skygzx</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">


  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
   <a href="https://skygzx.github.io/" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">skygzx</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home                   //首页"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user            //关于"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags		    //标签"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th    //分类"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive   //归档"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat    //公益404"></i> <br>
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/YARN生产上的优化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/YARN生产上的优化/" itemprop="url">YARN生产上的优化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T11:58:05+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<p><strong>1.yarn生产上的资源管理（至关重要）</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">	 假设一台机器：48物理内存  8个core--&gt;16个vcore</span><br><span class="line">	 Linux本身要占用内存+空留：20%=9.6个G（空留是根据实际机器的内存来决定的，如果内存大，可以考虑空留15%）</span><br><span class="line">	 剩余：80%=38.4G=38G</span><br><span class="line">	 DN进程：生产上4G</span><br><span class="line">	 	如何修改DN的内存配置信息：进入hadoop-env.sh脚本，</span><br><span class="line">	 	HADOOP_NAMENODE_OPTS=-Xmx1024m</span><br><span class="line">	 	HADOOP_DATANODE_OPTS=-Xmx1024m （在前面追加，如下图所示）</span><br><span class="line">	 NM进程：生产上4G</span><br><span class="line">	 	如何修改NM的内存配置信息：进入yarn-env.sh脚本，</span><br><span class="line">	 	export YARN_RESOURCEMANAGER_HEAPSIZE=1024</span><br><span class="line">	 	export YARN_NODEMANAGER_HEAPSIZE=1024 </span><br><span class="line">	 DN和NM部署在同一台机器上是为了：数据本地化</span><br><span class="line">	 NN RM 经常性部署同一台  说白了 集群节点少</span><br><span class="line">	 (正常情况下，DataNode进程和NodeManager进程部署在同一台机器： 数据本地化</span><br><span class="line">比如：在NM上运行task任务，task任务需要数据，数据是放在当前机器的hdfs上面的，发现当前</span><br><span class="line">有DataNode进程，节点上有需要的数据，那就只需要从当前节点拿数据就行了。但是如果发现当</span><br><span class="line">前机器上没有数据，要去另外的机器上拿数据，那就会通过网络，这时候会网络消耗，计算就会</span><br><span class="line">变慢了。）</span><br><span class="line"></span><br><span class="line">	 资源内存： 38G-4-4=30G（这30G是做什么？就是运行container容器）</span><br><span class="line">	 yarn.nodemanager.resource.memory-mb   30*1024MB（这是总的大小）</span><br><span class="line">	 默认配置</span><br><span class="line">	 yarn.scheduler.minimum-allocation-mb  1024 （最小可分配容器的大小）</span><br><span class="line">	 yarn.scheduler.maximum-allocation-mb  8192 （最大可分配容器的大小）</span><br><span class="line">	 （分配的容器的大小就是根据上面的参数来进行分配的）</span><br><span class="line">	 30G 30G/1G=30个container </span><br><span class="line">	 30G 30/8=3个container ...6G  (还留有6个G的内存被浪费掉)</span><br><span class="line">	 30个~3个（这样是不合理的）</span><br><span class="line"></span><br><span class="line">	 生产一：</span><br><span class="line">	 yarn.nodemanager.resource.memory-mb   30*1024MB</span><br><span class="line">	 yarn.scheduler.minimum-allocation-mb  2G</span><br><span class="line">	 yarn.scheduler.maximum-allocation-mb  30G</span><br><span class="line">	 15个~1个</span><br><span class="line">	 （这个是大作业的情况。要看每个公司的作业情况，如果作业特别大的情况，就设成和总的一样</span><br><span class="line">大）</span><br><span class="line">	（容器最小2G，就是这台机器最多可以运行15个容器，容器最大30G，就是这台机器最多可以运行1</span><br><span class="line">个容器。那这台机器可以运行1-15个容器。</span><br><span class="line">当你去请求资源的时候，它先给你分配一个最小的值，比如说2G，然后你如果不够，给你加比如</span><br><span class="line">说1G，直到加到最大比如说30G。（这个是有参数可以去配置的，在hadoop官网没有，在cdh官网</span><br><span class="line">是可以找到的）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	 生产二：</span><br><span class="line">	 yarn.nodemanager.resource.memory-mb   32G（可以将预留空间再缩小一点，这样留给container容器的空间会大一点）（这个由30G调整到32G，就需要从预留的20%里面</span><br><span class="line">拿出2G出来。这样32/8=4个容器，可以整除，不会浪费了）</span><br><span class="line"></span><br><span class="line">	 yarn.scheduler.minimum-allocation-mb  2G</span><br><span class="line">	 yarn.scheduler.maximum-allocation-mb  8G</span><br><span class="line">	 16个~4个</span><br><span class="line"></span><br><span class="line">	 生产三:</span><br><span class="line">	 如果物理机的内存是256G:（我们预留的空间可以按15%来算）</span><br><span class="line"></span><br><span class="line">	 yarn.nodemanager.resource.memory-mb   168G</span><br><span class="line">	 yarn.scheduler.minimum-allocation-mb  4G</span><br><span class="line">	 yarn.scheduler.maximum-allocation-mb  24G</span><br><span class="line">	 16个~4个</span><br><span class="line"></span><br><span class="line">	 再生产中很容易遇到这样一种情况：container p memory oom ：（意思是你的最大connertion内存不够用）</span><br><span class="line">	 遇到这种情况，我们首先先把这任务kill掉，然受修改参数，将分配的内存调大一些。</span><br><span class="line"></span><br><span class="line">	 生产默认 不做修改</span><br><span class="line">	 yarn.nodemanager.pmem-check-enabled	true   （表示如果 container tast任务超过内存 就会 kill 掉进程，</span><br><span class="line">	检查容器内存，一个是物理内存，一个是虚拟内存，虚拟内存是物理内存的</span><br><span class="line">	 2倍，哪个超了都会被kill 掉）</span><br><span class="line">	 yarn.nodemanager.vmem-check-enabled	true</span><br><span class="line">	 yarn.nodemanager.vmem-pmem-ratio	2.1</span><br><span class="line">	 物理内存 1m  虚拟内存 2.1m</span><br><span class="line"></span><br><span class="line">新版本参数</span><br><span class="line">yarn.nodemanager.resource.pcores-vcores-multiplier 1    （老的是2，现在是1，需要手动把它修改成2）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yarn.nodemanager.resource.memory-mb   </span><br><span class="line">yarn.scheduler.minimum-allocation-mb </span><br><span class="line">yarn.scheduler.maximum-allocation-mb </span><br><span class="line">这些参数的需要看官网里的默认配置yarn-default.xml。</span><br><span class="line">比如：yarn.nodemanager.resource.memory-mb如果设置成-1：</span><br><span class="line">Amount of physical memory, in MB, that can be allocated for containers. If set to -1and yarn.nodemanager.resource.detect-hardware-capabilities is true, it is automatically calculated(in case of Windows and Linux). In other cases, the default</span><br><span class="line">is 8192MB.</span><br><span class="line">yarn.nodemanager.resource.detect-hardware-capabilities：Enable auto-detection of nodecapabilities such as memory and CPU.（默认是false）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	 CPU:</span><br><span class="line">	 yarn.nodemanager.resource.cpu-vcores	 12（一般vcore是16个，但是我们还要分给其他进程。）</span><br><span class="line">	 yarn.scheduler.minimum-allocation-vcores  1</span><br><span class="line">	 yarn.scheduler.maximum-allocation-vcores  4</span><br><span class="line">	 </span><br><span class="line">	 container: 2G 3c</span><br><span class="line">	 container: </span><br><span class="line">	 memory 16c~4c</span><br><span class="line">	 vcores 12c~3c </span><br><span class="line">	 </span><br><span class="line"></span><br><span class="line">&gt; 生产调优的重点：</span><br><span class="line">&gt; 在生产中，运行task时所需要的资源需要由内存和vcore共同来决定，它俩时相互影响的，如果vcore</span><br><span class="line">&gt; 最小的只有3个crontainer，那么memory也只能分到3个crontainer，那么3*8=24G，还余6个G</span><br><span class="line">&gt; 的内存就会被浪费掉，所以yarn生产调优 需要计算好内存和vcore 的之间的数据。如果vore分给</span><br><span class="line">&gt; 它16个，那么vcore就可以分成16个~4个crontainer容易，最大利用了资源。</span><br></pre></td></tr></table></figure>
<p>详细可以参考 博客 ：<a href="http://blog.itpub.net/30089851/viewspace-2127851/" target="_blank" rel="noopener">http://blog.itpub.net/30089851/viewspace-2127851/</a><br><img src="https://img-blog.csdnimg.cn/20190312191451248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTg1MTQy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20190312183848248.png" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20190312184109600.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTg1MTQy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/[转载]MapReduce优化----Shuffle过程剖析及性能优化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/[转载]MapReduce优化----Shuffle过程剖析及性能优化/" itemprop="url">MapReduce优化----Shuffle过程剖析及性能优化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T11:02:43+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  9
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="1-Map端"><a href="#1-Map端" class="headerlink" title="1.    Map端"></a>1.    Map端</h2><p>当Map 开始产生输出时，它并不是简单的把数据写到磁盘，因为频繁的磁盘操作会导致性能严重下降。它的处理过程更复杂，数据首先是写到内存中的一个缓冲区，并做了一些预排序，以提升效率。</p>
<p>每个Map 任务都有一个用来写入输出数据的循环内存缓冲区。这个缓冲区默认大小是100MB，可以通过<strong>io.sort.mb</strong> 属性来设置具体大小。当缓冲区中的数据量达到一个特定阀值(io.sort.mb * io.sort.spill.percent，其中<strong>io.sort.spill.percent</strong> 默认是0.80)时，系统将会启动一个后台线程把缓冲区中的内容spill 到磁盘。在spill 过程中，Map 的输出将会继续写入到缓冲区，但如果缓冲区已满，Map 就会被阻塞直到spill 完成。spill 线程在把缓冲区的数据写到磁盘前，会对它进行一个二次快速排序，首先根据数据所属的partition 排序，然后每个partition 中再按Key 排序。输出包括一个索引文件和数据文件。</p>
<p>如果设定了Combiner，将在排序输出的基础上运行。Combiner 就是一个Mini Reducer，它在执行Map 任务的节点本身运行，先对Map 的输出做一次简单Reduce，使得Map 的输出更紧凑，更少的数据会被写入磁盘和传送到Reducer。</p>
<p>spill 文件保存在由<strong>mapred.local.dir</strong>指定的目录中，Map 任务结束后删除。</p>
<p>每当内存中的数据达到spill 阀值的时候，都会产生一个新的spill 文件，所以在Map任务写完它的最后一个输出记录时，可能会有多个spill 文件。在Map 任务完成前，所有的spill 文件将会被归并排序为一个索引文件和数据文件。这是一个多路归并过程，最大归并路数由<strong>io.sort.factor</strong> 控制(默认是10)。如果设定了Combiner，并且spill文件的数量至少是3（由min.num.spills.for.combine 属性控制），那么Combiner 将在输出文件被写入磁盘前运行以压缩数据。</p>
<p>对写入到磁盘的数据进行压缩，通常是一个很好的方法，因为这样做使得数据写入磁盘的速度更快，节省磁盘空间，并减少需要传送到Reducer 的数据量。默认输出是不被压缩的， 但可以很简单的设置<strong>mapred.compress.map.output</strong> 为true 启用该功能。压缩所使用的库由<strong>mapred.map.output.compression.codec</strong> 来设定。</p>
<p>当spill 文件归并完毕后，Map 将删除所有的临时spill 文件，并告知TaskTracker 任务已完成。Reducers 通过HTTP来获取对应的数据。用来传输partitions 数据的工作线程数由<strong>tasktracker.http.threads</strong> 控制，这个设定是针对每一个TaskTracker 的，并不是单个Map，默认值为40，在运行大作业的大集群上可以增大以提升数据传输速率。</p>
<h2 id="2-Reduce端"><a href="#2-Reduce端" class="headerlink" title="2.    Reduce端"></a>2.    Reduce端</h2><p>2.1 copy阶段</p>
<p>Map 的输出文件放置在运行Map 任务的TaskTracker 的本地磁盘上（注意：Map 输出总是写到本地磁盘，但Reduce 输出不是，一般是写到HDFS），它是运行Reduce 任务的TaskTracker 所需要的输入数据。Reduce 任务的输入数据分布在集群内的多个Map 任务的输出中，Map 任务可能会在不同的时间内完成，只要完成的Map 任务数达到占总Map任务数一定比例（<strong>mapred.reduce.slowstart.completed.maps</strong> 默认0.05），Reduce 任务就开始拷贝它的输出。</p>
<p>​         Reduce 任务拥有多个拷贝线程， 可以并行的获取Map 输出。可以通过设定<strong>mapred.reduce.parallel.copies</strong> 来改变线程数，默认是5。</p>
<p>如果Map 输出足够小，它们会被拷贝到Reduce TaskTracker 的内存中（缓冲区的大小</p>
<p>由<strong>mapred.job.shuffle.input.buffer.percent</strong> 控制，指定了用于此目的的堆内存的百分比）；如果缓冲区空间不足，会被拷贝到磁盘上。当内存中的缓冲区用量达到一定比例阀值（由<strong>mapred.job.shuffle.merge.percent</strong> 控制），或者达到了Map 输出的阀值大小（由<strong>mapred.inmem.merge.threshold</strong> 控制），缓冲区中的数据将会被归并然后spill到磁盘。</p>
<p>拷贝来的数据叠加在磁盘上，有一个后台线程会将它们归并为更大的排序文件，这样做节省了后期归并的时间。对于经过压缩的Map 输出，系统会自动把它们解压到内存方便对其执行归并。</p>
<p>2.2 sort阶段</p>
<p>当所有的Map 输出都被拷贝后，Reduce 任务进入排序阶段（更恰当的说应该是归并阶段，因为排序在Map 端就已经完成），这个阶段会对所有的Map 输出进行归并排序，这个工作会重复多次才能完成。</p>
<p>假设这里有50 个Map 输出（可能有保存在内存中的），并且归并因子是10（由<strong>io.sort.factor</strong> 控制，就像Map 端的merge 一样），那最终需要5 次归并。每次归并会把10个文件归并为一个，最终生成5 个中间文件。</p>
<p>注：每趟合并的文件数实际上比示例中展示的更微妙。目标是合并最小数量的文件以便满足最后一趟的合并系数。因此如果是40个文件，我们不会在四趟中，每趟合并10个文件从而得到4个文件。相反，第一趟只合并4个文件，随后三趟合并所有十个文件。在最后一趟中，4个已合并的文件和余下的6个（未合并的）文件合计10个文件。这并没有改变合并的次数，它只是一个优化措施，尽量减少写到磁盘的数据量，因为最后一趟总是直接合并到reduce。</p>
<p>2.3 reduce阶段</p>
<p>在Reduce 阶段，Reduce 函数会作用在排序输出的每一个key 上。这个阶段的输出被直接写到输出文件系统，一般是HDFS。在HDFS 中，因为TaskTracker 节点也运行着一个DataNode 进程，所以第一个块备份会直接写到本地磁盘。</p>
<h2 id="3-配置调优"><a href="#3-配置调优" class="headerlink" title="3.    配置调优"></a>3.    配置调优</h2><p>该配置调优方案主要是对以上Shuffle整个过程中涉及到的配置项按流程顺序一一呈现并给以调优建议。</p>
<p><strong>1. Map端</strong></p>
<p>1) io.sort.mb</p>
<p>用于map输出排序的内存缓冲区大小</p>
<p>类型：Int</p>
<p>默认：100mb</p>
<p>备注：如果能估算map输出大小，就可以合理设置该值来尽可能减少溢出写的次数，这对调优很有帮助。</p>
<p>2)io.sort.spill.percent</p>
<p>map输出排序时的spill阀值（即使用比例达到该值时，将缓冲区中的内容spill 到磁盘）</p>
<p>类型：float</p>
<p>默认：0.80</p>
<p>3)io.sort.factor</p>
<p>归并因子（归并时的最多合并的流数），map、reduce阶段都要用到</p>
<p>类型：Int</p>
<p>默认：10</p>
<p>备注：将此值增加到100是很常见的。</p>
<p>4)min.num.spills.for.combine</p>
<p>运行combiner所需的最少溢出写文件数（如果已指定combiner）</p>
<p>类型：Int</p>
<p>默认：3</p>
<p>5)mapred.compress.map.output</p>
<p>map输出是否压缩</p>
<p>类型：Boolean</p>
<p>默认：false</p>
<p>备注：如果map输出的数据量非常大，那么在写入磁盘时压缩数据往往是个很好的主意，因为这样会让写磁盘的速度更快，节约磁盘空间，并且减少传给reducer的数据量。</p>
<p>6)mapred.map.output.compression.codec</p>
<p>用于map输出的压缩编解码器</p>
<p>类型：Classname</p>
<p>默认：org.apache.<a href="http://lib.csdn.net/base/20" target="_blank" rel="noopener">Hadoop</a>.io.compress.DefaultCodec</p>
<p>备注：推荐使用LZO压缩。Intel内部测试表明，相比未压缩，使用LZO压缩的 TeraSort作业，运行时间减少60%，且明显快于Zlib压缩。</p>
<p>7) tasktracker.http.threads</p>
<p>每个tasktracker的工作线程数，用于将map输出到reducer。</p>
<p>（注：这是集群范围的设置，不能由单个作业设置）</p>
<p>类型：Int</p>
<p>默认：40</p>
<p>备注：tasktracker开http服务的线程数。用于reduce拉取map输出数据，大集群可以将其设为40~50。</p>
<p><strong>2. reduce端</strong></p>
<p>1)mapred.reduce.slowstart.completed.maps</p>
<p>调用reduce之前，map必须完成的最少比例</p>
<p>类型：float</p>
<p>默认：0.05</p>
<p>2)mapred.reduce.parallel.copies</p>
<p>reducer在copy阶段同时从mapper上拉取的文件数</p>
<p>类型：int</p>
<p>默认：5</p>
<p>3)mapred.job.shuffle.input.buffer.percent</p>
<p>在shuffle的复制阶段，分配给map输出的缓冲区占堆空间的百分比</p>
<p>类型：float</p>
<p>默认：0.70</p>
<p>4)mapred.job.shuffle.merge.percent</p>
<p>map输出缓冲区（由mapred.job.shuffle.input.buffer.percent定义）使用比例阀值，当达到此阀值，缓冲区中的数据将会被归并然后spill 到磁盘。</p>
<p>类型：float</p>
<p>默认：0.66</p>
<p>5)mapred.inmem.merge.threshold</p>
<p>map输出缓冲区中文件数</p>
<p>类型：int</p>
<p>默认：1000</p>
<p>备注：0或小于0的数意味着没有阀值限制，溢出写将有mapred.job.shuffle.merge.percent单独控制。</p>
<p>6)mapred.job.reduce.input.buffer.percent</p>
<p>在reduce过程中，在内存中保存map输出的空间占整个堆空间的比例。</p>
<p>类型：float</p>
<p>默认：0.0</p>
<p>备注：reduce阶段开始时，内存中的map输出大小不能大于该值。默认情况下，在reduce任务开始之前，所有的map输出都合并到磁盘上，以便为reducer提供尽可能多的内存。然而，如果reducer需要的内存较少，则可以增加此值来最小化访问磁盘的次数，以提高reduce性能。</p>
<p><strong>3.性能调优补充</strong></p>
<p>相对于大批量的小文件，hadoop更合适处理少量的大文件。一个原因是FileInputFormat生成的InputSplit是一个文件或该文件的一部分。如果文件很小，并且文件数量很多，那么每次map任务只处理很少的输入数据，每次map操作都会造成额外的开销。</p>
<p>转自：<a href="http://blog.itpub.net/30089851/viewspace-2122878/" target="_blank" rel="noopener">http://blog.itpub.net/30089851/viewspace-2122878/</a></p>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/[转载]Hadoop-2.7.2+zookeeper-3.4.6完全分布式环境搭建(HDFS、YARN HA)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/[转载]Hadoop-2.7.2+zookeeper-3.4.6完全分布式环境搭建(HDFS、YARN HA)/" itemprop="url">Hadoop-2.7.2+zookeeper-3.4.6完全分布式环境搭建(HDFS、YARN HA)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T10:58:32+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  23
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<p>Hadoop-2.7.2+Zookeeper-3.4.6完全分布式环境搭建</p>
<p><strong>一.版本</strong></p>
<table>
<thead>
<tr>
<th>组件名</th>
<th>版本</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>JRE</td>
<td>java version “1.7.0_67” Java™ SE Runtime Environment (build 1.7.0_67-b01) Java HotSpot™ 64-Bit Server VM (build 24.65-b04, mixed mode)</td>
<td></td>
</tr>
<tr>
<td>Hadoop</td>
<td>hadoop-2.7.2.tar.gz</td>
<td>主程序包</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>zookeeper-3.4.6.tar.gz</td>
<td>热切,Yarn 存储数据使用的协调服务</td>
</tr>
</tbody>
</table>
<p>二.主机规划</p>
<table>
<thead>
<tr>
<th>IP</th>
<th>Host 及安装软件</th>
<th>部署模块</th>
<th>进程</th>
</tr>
</thead>
<tbody>
<tr>
<td>172.16.101.55</td>
<td>sht-sgmhadoopnn-01 hadoop</td>
<td>NameNode ResourceManager</td>
<td>NameNode DFSZKFailoverController ResourceManager</td>
</tr>
<tr>
<td>172.16.101.56</td>
<td>sht-sgmhadoopnn-02 hadoop</td>
<td>NameNode ResourceManager</td>
<td>NameNode DFSZKFailoverController ResourceManager</td>
</tr>
<tr>
<td>172.16.101.58</td>
<td>sht-sgmhadoopdn-01 hadoop、zookeeper</td>
<td>DataNode NodeManager Zookeeper</td>
<td>DataNode NodeManager JournalNode QuorumPeerMain</td>
</tr>
<tr>
<td>172.16.101.59</td>
<td>sht-sgmhadoopdn-02 Hadoop、zookeeper</td>
<td>DataNode NodeManager Zookeeper</td>
<td>DataNode NodeManager JournalNode QuorumPeerMain</td>
</tr>
<tr>
<td>172.16.101.60</td>
<td>sht-sgmhadoopdn-03 Hadoop、zookeeper</td>
<td>DataNode NodeManager Zookeeper</td>
<td>DataNode NodeManager JournalNode QuorumPeerMain</td>
</tr>
</tbody>
</table>
<p>三.目录规划</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>路径</th>
</tr>
</thead>
<tbody>
<tr>
<td>$HADOOP_HOME</td>
<td>/hadoop/hadoop-2.7.2</td>
</tr>
<tr>
<td>Data</td>
<td>$ HADOOP_HOME/data</td>
</tr>
<tr>
<td>Log</td>
<td>$ HADOOP_HOME/logs</td>
</tr>
</tbody>
</table>
<p>四.常用脚本及命令</p>
<p>1.启动集群</p>
<p><a href="http://start-dfs.sh" target="_blank" rel="noopener">start-dfs.sh</a></p>
<p><a href="http://start-yarn.sh" target="_blank" rel="noopener">start-yarn.sh</a></p>
<p>2.关闭集群</p>
<p><a href="http://stop-yarn.sh" target="_blank" rel="noopener">stop-yarn.sh</a></p>
<p><a href="http://stop-dfs.sh" target="_blank" rel="noopener">stop-dfs.sh</a></p>
<p>3.监控集群</p>
<p>hdfs dfsadmin -report</p>
<p>4.单个进程启动/关闭</p>
<p><a href="http://hadoop-daemon.sh" target="_blank" rel="noopener">hadoop-daemon.sh</a> start|stop namenode|datanode| journalnode</p>
<p><a href="http://yarn-daemon.sh" target="_blank" rel="noopener">yarn-daemon.sh</a> start |stop resourcemanager|nodemanager</p>
<p><a href="http://blog.chinaunix.net/uid-25723371-id-4943894.html" target="_blank" rel="noopener">http://blog.chinaunix.net/uid-25723371-id-4943894.html</a></p>
<p>五.环境准备</p>
<p><strong>*1 .**</strong>设置<strong><strong>ip</strong></strong>地址<strong><strong>(5</strong></strong>台<strong>*<em>)</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0</em></li>
<li><em>DEVICE=”eth0”</em></li>
<li><em>BOOTPROTO=”static”</em></li>
<li><em>DNS1=”172.16.101.63”</em></li>
<li><em>DNS2=”172.16.101.64”</em></li>
<li><em>GATEWAY=”172.16.101.1”</em></li>
<li><em>HWADDR=”00:50:56:82:50:1E”</em></li>
<li><em>IPADDR=”172.16.101.55”</em></li>
<li><em>NETMASK=”255.255.255.0”</em></li>
<li><em>NM_CONTROLLED=”yes”</em></li>
<li><em>ONBOOT=”yes”</em></li>
<li><em>TYPE=”Ethernet”</em></li>
<li><em>UUID=”257c075f-6c6a-47ef-a025-e625367cbd9c”</em></li>
</ol>
<p><em>执行命令: service network restart</em></p>
<p><em>验证:ifconfig</em></p>
<p><strong>*2 .**</strong>关闭防火墙<strong><strong>(5</strong></strong>台<strong>*<em>)</em></strong></p>
<p><em>执行命:service iptables stop</em></p>
<p><em>验证:service iptables status</em></p>
<p><strong>*3.**</strong>关闭防火墙的自动运行<strong><strong>(5</strong></strong>台<strong>*<em>)</em></strong></p>
<p><em>执行命令:chkconfig iptables off</em></p>
<p><em>验证:chkconfig –list | grep iptables</em></p>
<p><strong>*4</strong> <strong>设置主机名**</strong>(5<strong><strong>台</strong></strong>)***</p>
<p><em>执行命令 (1)hostname sht-sgmhadoopnn-01</em></p>
<p><em>(2)vi /etc/sysconfig/network</em></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 ~]# vi /etc/sysconfig/network</em></li>
<li><em>NETWORKING=yes</em></li>
<li><em>HOSTNAME=sht-sgmhadoopnn-01.telenav.cn</em></li>
<li><em>GATEWAY=172.16.101.1</em></li>
</ol>
<p><strong>*5 ip**</strong>与<strong><strong>hostname</strong></strong>绑定<strong><strong>(5</strong></strong>台<strong>*<em>)</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 ~]# vi /etc/hosts</em></li>
<li><em>127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4</em></li>
<li><em>::1 localhost localhost.localdomain localhost6 localhost6.localdomain6</em></li>
<li><em>172.16.101.55 sht-sgmhadoopnn-01.telenav.cn sht-sgmhadoopnn-01</em></li>
<li><em>172.16.101.56 sht-sgmhadoopnn-02.telenav.cn sht-sgmhadoopnn-02</em></li>
<li><em>172.16.101.58 sht-sgmhadoopdn-01.telenav.cn sht-sgmhadoopdn-01</em></li>
<li><em>172.16.101.59 sht-sgmhadoopdn-02.telenav.cn sht-sgmhadoopdn-02</em></li>
<li><em>172.16.101.60 sht-sgmhadoopdn-03.telenav.cn sht-sgmhadoopdn-03</em></li>
<li><em>验证:ping sht-sgmhadoopnn-01</em></li>
</ol>
<p><strong>*6.</strong> <strong>设置**</strong>5<strong><strong>台</strong></strong>machines,<strong><strong>SSH</strong></strong>互相通信<strong>*<em><a href="http://blog.itpub.net/30089851/viewspace-1992210/" target="_blank" rel="noopener">http://blog.itpub.net/30089851/viewspace-1992210/</a></em></strong></p>
<p><strong>*7 .**</strong>安装<strong><strong>JDK(5</strong></strong>台<strong>*<em>)</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>(1)执行命令</em></li>
<li><em>[root@sht-sgmhadoopnn-01 ~]# cd /usr/java</em></li>
<li><em>[root@sht-sgmhadoopnn-01 java]# cp /tmp/jdk-7u67-linux-x64.gz ./</em></li>
<li><em>[root@sht-sgmhadoopnn-01 java]# tar -xzvf jdk-7u67-linux-x64.gz</em></li>
<li><em>(2)vi /etc/profile 增加内容如下:</em></li>
<li><em>export JAVA_HOME=/usr/java/jdk1.7.0_67</em></li>
<li><em>export HADOOP_HOME=/hadoop/hadoop-2.7.2</em></li>
<li><em>export ZOOKEEPER_HOME=/hadoop/zookeeper</em></li>
<li><em>export PATH=.:$HADOOP_HOME/bin:$JAVA_HOME/bin:$ZOOKEEPER_HOME/bin:$PATH</em></li>
<li><em>#先把HADOOP_HOME, ZOOKEEPER_HOME配置了</em></li>
<li><em>#本次实验机器已经配置好了jdk1.7.0_67-cloudera</em></li>
<li><em>(3)执行 source /etc/profile</em></li>
<li><em>(4)验证:java –version</em></li>
</ol>
<p><strong>*8.**</strong>创建文件夹<strong><strong>(5</strong></strong>台<strong>*<em>)</em></strong></p>
<p><em>mkdir /hadoop</em></p>
<p><strong>*六**</strong>.<strong><strong>安装</strong></strong>Zookeeper***</p>
<p><strong>*sht-sgmhadoopdn-01/02/03*</strong></p>
<p><strong>*1.**</strong>下载解压<strong>*<em>zookeeper-3.4.6.tar.gz</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopdn-01 tmp]# wget <a href="http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz</a></em></li>
<li><em>[root@sht-sgmhadoopdn-02 tmp]# wget <a href="http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz</a></em></li>
<li><em>[root@sht-sgmhadoopdn-03 tmp]# wget <a href="http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz</a></em></li>
<li><em>[root@sht-sgmhadoopdn-01 tmp]# tar -xvf zookeeper-3.4.6.tar.gz</em></li>
<li><em>[root@sht-sgmhadoopdn-02 tmp]# tar -xvf zookeeper-3.4.6.tar.gz</em></li>
<li><em>[root@sht-sgmhadoopdn-03 tmp]# tar -xvf zookeeper-3.4.6.tar.gz</em></li>
<li><em>[root@sht-sgmhadoopdn-01 tmp]# mv zookeeper-3.4.6 /hadoop/zookeeper</em></li>
<li><em>[root@sht-sgmhadoopdn-02 tmp]# mv zookeeper-3.4.6 /hadoop/zookeeper</em></li>
<li><em>[root@sht-sgmhadoopdn-03 tmp]# mv zookeeper-3.4.6 /hadoop/zookeeper</em></li>
</ol>
<p><strong>*2.**</strong>修改配置***</p>
<p><strong>*点击(此处)折叠或打开*</strong></p>
<ol>
<li><strong>*[root@sht-sgmhadoopdn-01 tmp]# cd /hadoop/zookeeper/conf*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-01 conf]# cp zoo_sample.cfg zoo.cfg*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-01 conf]# vi zoo.cfg*</strong></li>
<li><strong>*修改dataDir*</strong></li>
<li><strong>*dataDir=/hadoop/zookeeper/data*</strong></li>
<li><strong>*添加下面三行*</strong></li>
<li><strong>*server.1=sht-sgmhadoopdn-01:2888:3888*</strong></li>
<li><strong>*server.2=sht-sgmhadoopdn-02:2888:3888*</strong></li>
<li><strong>*server.3=sht-sgmhadoopdn-03:2888:3888*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-01 conf]# cd ../*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-01 zookeeper]# mkdir data*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-01 zookeeper]# touch data/myid*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-01 zookeeper]# echo 1 &gt; data/myid*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-01 zookeeper]# more data/myid*</strong></li>
<li><strong>*1*</strong></li>
<li><strong>*## sht-sgmhadoopdn-02/03,也修改配置,就如下不同*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-02 zookeeper]# echo 2 &gt; data/myid*</strong></li>
<li><strong>*[root@sht-sgmhadoopdn-03 zookeeper]# echo 3 &gt; data/myid*</strong></li>
</ol>
<p><strong>*七**</strong>.<strong><strong>安装</strong></strong>Hadoop(HDFS HA+YARN HA)***</p>
<p><strong>*#step3~7,**</strong>用<strong>**SecureCRT ssh</strong> <strong>到</strong> <strong>linux**</strong>的环境中<strong><strong>,</strong></strong>假如<strong>**copy</strong> <strong>内容从**</strong>window<strong> </strong>到<strong> </strong>linux<strong> </strong>中<strong><strong>,</strong></strong>中文乱码<strong><strong>,</strong></strong>请参照修改*<em><a href="http://www.cnblogs.com/qi09/archive/2013/02/05/2892922.html" target="_blank" rel="noopener">http://www.cnblogs.com/qi09/archive/2013/02/05/2892922.html</a></em></p>
<p><strong>*1.**</strong>下载解压<strong>*<em>hadoop-2.7.2.tar.gz</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopdn-01 tmp]# cd /hadoop/zookeeper/conf</em></li>
<li><em>[root@sht-sgmhadoopdn-01 conf]# cp zoo_sample.cfg zoo.cfg</em></li>
<li><em>[root@sht-sgmhadoopdn-01 conf]# vi zoo.cfg</em></li>
<li><em>修改dataDir</em></li>
<li><em>dataDir=/hadoop/zookeeper/data</em></li>
<li><em>添加下面三行</em></li>
<li><em>server.1=sht-sgmhadoopdn-01:2888:3888</em></li>
<li><em>server.2=sht-sgmhadoopdn-02:2888:3888</em></li>
<li><em>server.3=sht-sgmhadoopdn-03:2888:3888</em></li>
<li><em>[root@sht-sgmhadoopdn-01 conf]# cd ../</em></li>
<li><em>[root@sht-sgmhadoopdn-01 zookeeper]# mkdir data</em></li>
<li><em>[root@sht-sgmhadoopdn-01 zookeeper]# touch data/myid</em></li>
<li><em>[root@sht-sgmhadoopdn-01 zookeeper]# echo 1 &gt; data/myid</em></li>
<li><em>[root@sht-sgmhadoopdn-01 zookeeper]# more data/myid</em></li>
<li><em>1</em></li>
<li><em>## sht-sgmhadoopdn-02/03,也修改配置,就如下不同</em></li>
<li><em>[root@sht-sgmhadoopdn-02 zookeeper]# echo 2 &gt; data/myid</em></li>
<li><em>[root@sht-sgmhadoopdn-03 zookeeper]# echo 3 &gt; data/myid</em></li>
</ol>
<p><strong>*2.**</strong>修改<strong>*<em>$HADOOP_HOME/etc/hadoop/hadoop-env.sh</em></strong></p>
<p><em>export JAVA_HOME=”/usr/java/jdk1.7.0_67-cloudera”</em></p>
<p><strong>*3.**</strong>修改<strong>*<em>$HADOOP_HOME/etc/hadoop/core-site.xml</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;</em></li>
<li><em>&lt;?xml-stylesheet type=”text/xsl” href=”configuration.xsl”?&gt;</em></li>
<li><em><configuration></configuration></em></li>
<li>​    <em><!--Yarn 需要使用 fs.defaultFS 指定NameNode URI --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>fs.defaultFS</name></em></li>
<li>​        <em><value>hdfs://mycluster</value></em></li>
<li>​    <em></em></li>
<li>​    <em><!--HDFS超级用户 --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.permissions.superusergroup</name></em></li>
<li>​        <em><value>root</value></em></li>
<li>​    <em></em></li>
<li>​    <em><!--==============================Trash机制======================================= --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><!--多长时间创建CheckPoint NameNode截点上运行的CheckPointer 从Current文件夹创建CheckPoint;默认：0 由fs.trash.interval项指定 --></em></li>
<li>​        <em><name>fs.trash.checkpoint.interval</name></em></li>
<li>​        <em><value>0</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><!--多少分钟.Trash下的CheckPoint目录会被删除,该配置服务器设置优先级大于客户端，默认：0 不删除 --></em></li>
<li>​        <em><name>fs.trash.interval</name></em></li>
<li>​        <em><value>1440</value></em></li>
<li>​    <em></em></li>
<li><em></em></li>
</ol>
<p><strong>*4.**</strong>修改<strong><strong>$HADOOP_HOME/etc/</strong></strong>hadoop/hdfs-site.xml***</p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;</em></li>
<li><em>&lt;?xml-stylesheet type=”text/xsl” href=”configuration.xsl”?&gt;</em></li>
<li><em><configuration></configuration></em></li>
<li>​    <em><!--开启web hdfs --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.webhdfs.enabled</name></em></li>
<li>​        <em><value>true</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.namenode.name.dir</name></em></li>
<li>​        <em><value>/hadoop/hadoop-2.7.2/data/dfs/name</value></em></li>
<li>​        <em><description> namenode 存放name table(fsimage)本地目录（需要修改）</description></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.namenode.edits.dir</name></em></li>
<li>​        <em><value>${dfs.namenode.name.dir}</value></em></li>
<li>​        <em><description>namenode粗放 transaction file(edits)本地目录（需要修改）</description></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.datanode.data.dir</name></em></li>
<li>​        <em><value>/hadoop/hadoop-2.7.2/data/dfs/data</value></em></li>
<li>​        <em><description>datanode存放block本地目录（需要修改）</description></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.replication</name></em></li>
<li>​        <em><value>3</value></em></li>
<li>​    <em></em></li>
<li>​    <em><!-- 块大小 （默认） --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.blocksize</name></em></li>
<li>​        <em><value>268435456</value></em></li>
<li>​    <em></em></li>
<li>​    <em><!--======================================================================= --></em></li>
<li>​    <em><!--HDFS高可用配置 --></em></li>
<li>​    <em><!--nameservices逻辑名 --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.nameservices</name></em></li>
<li>​        <em><value>mycluster</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><!--设置NameNode IDs 此版本最大只支持两个NameNode --></em></li>
<li>​        <em><name>dfs.ha.namenodes.mycluster</name></em></li>
<li>​        <em><value>nn1,nn2</value></em></li>
<li>​    <em></em></li>
<li></li>
<li>​    <em><!-- Hdfs HA: dfs.namenode.rpc-address.[nameservice ID] rpc 通信地址 --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.namenode.rpc-address.mycluster.nn1</name></em></li>
<li>​        <em><value>sht-sgmhadoopnn-01:8020</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.namenode.rpc-address.mycluster.nn2</name></em></li>
<li>​        <em><value>sht-sgmhadoopnn-02:8020</value></em></li>
<li>​    <em></em></li>
<li></li>
<li>​    <em><!-- Hdfs HA: dfs.namenode.http-address.[nameservice ID] http 通信地址 --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.namenode.http-address.mycluster.nn1</name></em></li>
<li>​        <em><value>sht-sgmhadoopnn-01:50070</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.namenode.http-address.mycluster.nn2</name></em></li>
<li>​        <em><value>sht-sgmhadoopnn-02:50070</value></em></li>
<li>​    <em></em></li>
<li></li>
<li>​    <em><!--==================Namenode editlog同步 ============================================ --></em></li>
<li>​    <em><!--保证数据恢复 --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.journalnode.http-address</name></em></li>
<li>​        <em><value>0.0.0.0:8480</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.journalnode.rpc-address</name></em></li>
<li>​        <em><value>0.0.0.0:8485</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><!--设置JournalNode服务器地址，QuorumJournalManager 用于存储editlog --></em></li>
<li>​        <em><!--格式：qjournal://<host1:port1>;<host2:port2>;<host3:port3>/<journalId> 端口同journalnode.rpc-address --></em></li>
<li>​        <em><name>dfs.namenode.shared.edits.dir</name></em></li>
<li>​        <em><value>qjournal://sht-sgmhadoopdn-01:8485;sht-sgmhadoopdn-02:8485;sht-sgmhadoopdn-03:8485/mycluster</value></em></li>
<li>​    <em></em></li>
<li></li>
<li>​    <em><property></property></em></li>
<li>​        <em><!--JournalNode存放数据地址 --></em></li>
<li>​        <em><name>dfs.journalnode.edits.dir</name></em></li>
<li>​        <em><value>/hadoop/hadoop-2.7.2/data/dfs/jn</value></em></li>
<li>​    <em></em></li>
<li>​    <em><!--==================DataNode editlog同步 ============================================ --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><!--DataNode,Client连接Namenode识别选择Active NameNode策略 --></em></li>
<li>​        <em><name>dfs.client.failover.proxy.provider.mycluster</name></em></li>
<li>​        <em><value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value></em></li>
<li>​    <em></em></li>
<li>​    <em><!--==================Namenode fencing：=============================================== --></em></li>
<li>​    <em><!--Failover后防止停掉的Namenode启动，造成两个服务 --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.ha.fencing.methods</name></em></li>
<li>​        <em><value>sshfence</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.ha.fencing.ssh.private-key-files</name></em></li>
<li>​        <em><value>/root/.ssh/id_rsa</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><!--多少milliseconds 认为fencing失败 --></em></li>
<li>​        <em><name>dfs.ha.fencing.ssh.connect-timeout</name></em></li>
<li>​        <em><value>30000</value></em></li>
<li>​    <em></em></li>
<li></li>
<li>​    <em><!--==================NameNode auto failover base ZKFC and Zookeeper====================== --></em></li>
<li>​    <em><!--开启基于Zookeeper及ZKFC进程的自动备援设置,监视进程是否死掉 --></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>dfs.ha.automatic-failover.enabled</name></em></li>
<li>​        <em><value>true</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><name>ha.zookeeper.quorum</name></em></li>
<li>​        <em><value>sht-sgmhadoopdn-01:2181,sht-sgmhadoopdn-02:2181,sht-sgmhadoopdn-03:2181</value></em></li>
<li>​    <em></em></li>
<li>​    <em><property></property></em></li>
<li>​        <em><!--指定ZooKeeper超时间隔，单位毫秒 --></em></li>
<li>​        <em><name>ha.zookeeper.session-timeout.ms</name></em></li>
<li>​        <em><value>2000</value></em></li>
<li>​    <em></em></li>
<li><em></em></li>
</ol>
<p><strong>*5.**</strong>修改<strong><strong>$HADOOP_HOME/etc/</strong></strong>hadoop/yarn-env.sh***</p>
<p><em>#Yarn Daemon Options</em></p>
<p><em>#export YARN_RESOURCEMANAGER_OPTS</em></p>
<p><em>#export YARN_NODEMANAGER_OPTS</em></p>
<p><em>#export YARN_PROXYSERVER_OPTS</em></p>
<p><em>#export HADOOP_JOB_HISTORYSERVER_OPTS</em></p>
<p><em>#Yarn Logs</em></p>
<p><em>export YARN_LOG_DIR=”/hadoop/hadoop-2.7.2/logs”</em></p>
<p><strong>*6.**</strong>修改<strong><strong>$HADOOP_HOEM/etc/</strong></strong>hadoop/mapred-site.xml***</p>
<p><strong>*点击(此处)折叠或打开*</strong></p>
<ol>
<li><strong>*[root@sht-sgmhadoopnn-01 hadoop]# cp mapred-site.xml.template mapred-site.xml*</strong></li>
<li><strong>*[root@sht-sgmhadoopnn-01 hadoop]# vi mapred-site.xml*</strong></li>
<li><strong>*<configuration>*</configuration></strong></li>
<li>​    <strong>*<!-- 配置 MapReduce Applications -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>mapreduce.framework.name</name>*</strong></li>
<li>​        <strong>*<value>yarn</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- JobHistory Server ============================================================== -->*</strong></li>
<li>​    <strong>*<!-- 配置 MapReduce JobHistory Server 地址 ，默认: 0.0.0.0:10020 -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>mapreduce.jobhistory.address</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-01:10020</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- 配置 MapReduce JobHistory Server web ui 地址， 默认: 0.0.0.0:19888 -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>mapreduce.jobhistory.webapp.address</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-01:19888</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li><strong>**</strong></li>
</ol>
<p><strong>*7.**</strong>修改<strong><strong>$HADOOP_HOME/etc/</strong></strong>hadoop/yarn-site.xml***</p>
<p><strong>*点击(此处)折叠或打开*</strong></p>
<ol>
<li><strong>*<configuration>*</configuration></strong></li>
<li>​    <strong>*<!-- nodemanager 配置 ================================================= -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.nodemanager.aux-services</name>*</strong></li>
<li>​        <strong>*<value>mapreduce_shuffle</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>*</strong></li>
<li>​        <strong>*<value>org.apache.hadoop.mapred.ShuffleHandler</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<description>Address where the localizer IPC is.</description>*</strong></li>
<li>​        <strong>*<name>yarn.nodemanager.localizer.address</name>*</strong></li>
<li>​        <strong>*<value>0.0.0.0:23344</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<description>NM Webapp address.</description>*</strong></li>
<li>​        <strong>*<name>yarn.nodemanager.webapp.address</name>*</strong></li>
<li>​        <strong>*<value>0.0.0.0:23999</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li></li>
<li>​    <strong>*<!-- HA 配置 =============================================================== -->*</strong></li>
<li>​    <strong>*<!-- Resource Manager Configs -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.connect.retry-interval.ms</name>*</strong></li>
<li>​        <strong>*<value>2000</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.ha.enabled</name>*</strong></li>
<li>​        <strong>*<value>true</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.ha.automatic-failover.enabled</name>*</strong></li>
<li>​        <strong>*<value>true</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- 使嵌入式自动故障转移。HA环境启动，与 ZKRMStateStore 配合 处理fencing -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.ha.automatic-failover.embedded</name>*</strong></li>
<li>​        <strong>*<value>true</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- 集群名称，确保HA选举时对应的集群 -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.cluster-id</name>*</strong></li>
<li>​        <strong>*<value>yarn-cluster</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.ha.rm-ids</name>*</strong></li>
<li>​        <strong>*<value>rm1,rm2</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*&lt;!–这里RM主备结点需要单独指定,（可选）*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.ha.id</name>*</strong></li>
<li>​        <strong>*<value>rm2</value>*</strong></li>
<li><strong>**</strong></li>
<li><strong>*–&gt;*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.scheduler.class</name>*</strong></li>
<li>​        <strong>*<value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.recovery.enabled</name>*</strong></li>
<li>​        <strong>*<value>true</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.app.mapreduce.am.scheduler.connection.wait.interval-ms</name>*</strong></li>
<li>​        <strong>*<value>5000</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- ZKRMStateStore 配置 -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.store.class</name>*</strong></li>
<li>​        <strong>*<value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.zk-address</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopdn-01:2181,sht-sgmhadoopdn-02:2181,sht-sgmhadoopdn-03:2181</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.zk.state-store.address</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopdn-01:2181,sht-sgmhadoopdn-02:2181,sht-sgmhadoopdn-03:2181</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- Client访问RM的RPC地址 (applications manager interface) -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.address.rm1</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-01:23140</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.address.rm2</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-02:23140</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- AM访问RM的RPC地址(scheduler interface) -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.scheduler.address.rm1</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-01:23130</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.scheduler.address.rm2</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-02:23130</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- RM admin interface -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.admin.address.rm1</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-01:23141</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.admin.address.rm2</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-02:23141</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!--NM访问RM的RPC端口 -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.resource-tracker.address.rm1</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-01:23125</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.resource-tracker.address.rm2</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-02:23125</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<!-- RM web application 地址 -->*</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.webapp.address.rm1</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-01:8088</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.webapp.address.rm2</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-02:8088</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.webapp.https.address.rm1</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-01:23189</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li>​    <strong>*<property>*</property></strong></li>
<li>​        <strong>*<name>yarn.resourcemanager.webapp.https.address.rm2</name>*</strong></li>
<li>​        <strong>*<value>sht-sgmhadoopnn-02:23189</value>*</strong></li>
<li>​    <strong>**</strong></li>
<li><strong>**</strong></li>
</ol>
<p><strong>*8.**</strong>修改<strong>*<em>slaves</em></strong></p>
<p><em>[root@sht-sgmhadoopnn-01 hadoop]# vi slaves</em></p>
<p><em>sht-sgmhadoopdn-01</em></p>
<p><em>sht-sgmhadoopdn-02</em></p>
<p><em>sht-sgmhadoopdn-03</em></p>
<p><strong>*9.**</strong>分发文件夹***</p>
<p><em>[root@sht-sgmhadoopnn-01 hadoop]# scp -r hadoop-2.7.2 root@sht-sgmhadoopnn-02:/hadoop</em></p>
<p><em>[root@sht-sgmhadoopnn-01 hadoop]# scp -r hadoop-2.7.2 root@sht-sgmhadoopdn-01:/hadoop</em></p>
<p><em>[root@sht-sgmhadoopnn-01 hadoop]# scp -r hadoop-2.7.2 root@sht-sgmhadoopdn-02:/hadoop</em></p>
<p><em>[root@sht-sgmhadoopnn-01 hadoop]# scp -r hadoop-2.7.2 root@sht-sgmhadoopdn-03:/hadoop</em></p>
<p><strong>*八**</strong>.<strong>*<em>启动集群</em></strong></p>
<p><em>另外一种启动方式:<a href="http://www.micmiu.com/bigdata/hadoop/hadoop2-cluster-ha-setup/" target="_blank" rel="noopener">http://www.micmiu.com/bigdata/hadoop/hadoop2-cluster-ha-setup/</a></em></p>
<p><strong>*1.**</strong>启动<strong>*<em>zookeeper</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>command: ./zkServer.sh start|stop|status</em></li>
<li><em>[root@sht-sgmhadoopdn-01 bin]# ./zkServer.sh start</em></li>
<li><em>JMX enabled by default</em></li>
<li><em>Using config: /hadoop/zookeeper/bin/../conf/zoo.cfg</em></li>
<li><em>Starting zookeeper … STARTED</em></li>
<li><em>[root@sht-sgmhadoopdn-01 bin]# jps</em></li>
<li><em>2073 QuorumPeerMain</em></li>
<li><em>2106 Jps</em></li>
<li><em>[root@sht-sgmhadoopdn-02 bin]# ./zkServer.sh start</em></li>
<li><em>JMX enabled by default</em></li>
<li><em>Using config: /hadoop/zookeeper/bin/../conf/zoo.cfg</em></li>
<li><em>Starting zookeeper … STARTED</em></li>
<li><em>[root@sht-sgmhadoopdn-02 bin]# jps</em></li>
<li><em>2073 QuorumPeerMain</em></li>
<li><em>2106 Jps</em></li>
<li><em>[root@sht-sgmhadoopdn-03 bin]# ./zkServer.sh start</em></li>
<li><em>JMX enabled by default</em></li>
<li><em>Using config: /hadoop/zookeeper/bin/../conf/zoo.cfg</em></li>
<li><em>Starting zookeeper … STARTED</em></li>
<li><em>[root@sht-sgmhadoopdn-03 bin]# jps</em></li>
<li><em>2073 QuorumPeerMain</em></li>
<li><em>2106 Jps</em></li>
</ol>
<p><strong>*2.**</strong>启动<strong>*<em>hadoop(HDFS+YARN)</em></strong></p>
<p><strong>*a.**</strong>格式化前<strong><strong>,</strong></strong>先在<strong>**journalnode</strong> <strong>节点机器上先启动**</strong>JournalNode<strong>*<em>进程</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopdn-01 ~]# cd /hadoop/hadoop-2.7.2/sbin</em></li>
<li><em>[root@sht-sgmhadoopdn-01 sbin]# hadoop-daemon.sh start journalnode</em></li>
<li><em>starting journalnode, logging to /hadoop/hadoop-2.7.2/logs/hadoop-root-journalnode-sht-sgmhadoopdn-03.telenav.cn.out</em></li>
<li><em>[root@sht-sgmhadoopdn-03 sbin]# jps</em></li>
<li><em>16722 JournalNode</em></li>
<li><em>16775 Jps</em></li>
<li><em>15519 QuorumPeerMain</em></li>
<li><em>[root@sht-sgmhadoopdn-02 ~]# cd /hadoop/hadoop-2.7.2/sbin</em></li>
<li><em>[root@sht-sgmhadoopdn-02 sbin]# hadoop-daemon.sh start journalnode</em></li>
<li><em>starting journalnode, logging to /hadoop/hadoop-2.7.2/logs/hadoop-root-journalnode-sht-sgmhadoopdn-03.telenav.cn.out</em></li>
<li><em>[root@sht-sgmhadoopdn-03 sbin]# jps</em></li>
<li><em>16722 JournalNode</em></li>
<li><em>16775 Jps</em></li>
<li><em>15519 QuorumPeerMain</em></li>
<li><em>[root@sht-sgmhadoopdn-03 ~]# cd /hadoop/hadoop-2.7.2/sbin</em></li>
<li><em>[root@sht-sgmhadoopdn-03 sbin]# hadoop-daemon.sh start journalnode</em></li>
<li><em>starting journalnode, logging to /hadoop/hadoop-2.7.2/logs/hadoop-root-journalnode-sht-sgmhadoopdn-03.telenav.cn.out</em></li>
<li><em>[root@sht-sgmhadoopdn-03 sbin]# jps</em></li>
<li><em>16722 JournalNode</em></li>
<li><em>16775 Jps</em></li>
<li><em>15519 QuorumPeerMain</em></li>
</ol>
<p><strong>*b.NameNode**</strong>格式化***</p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 bin]# hadoop namenode -format</em></li>
<li><em>16/02/25 14:05:04 INFO namenode.NameNode: STARTUP_MSG:</em></li>
<li><em>/*<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>***</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></li>
<li><em>STARTUP_MSG: Starting NameNode</em></li>
<li><em>STARTUP_MSG: host = sht-sgmhadoopnn-01.telenav.cn/172.16.101.55</em></li>
<li><em>STARTUP_MSG: args = [-format]</em></li>
<li><em>STARTUP_MSG: version = 2.7.2</em></li>
<li><em>STARTUP_MSG: classpath =</em></li>
<li><em>……………..</em></li>
<li><em>………………</em></li>
<li><em>16/02/25 14:05:07 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033</em></li>
<li><em>16/02/25 14:05:07 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0</em></li>
<li><em>16/02/25 14:05:07 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension = 30000</em></li>
<li><em>16/02/25 14:05:07 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10</em></li>
<li><em>16/02/25 14:05:07 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10</em></li>
<li><em>16/02/25 14:05:07 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25</em></li>
<li><em>16/02/25 14:05:07 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</em></li>
<li><em>16/02/25 14:05:07 INFO namenode.FSNamesystem: Retry cache will  use 0.03 of total heap and retry cache entry expiry time is 600000  millis</em></li>
<li><em>16/02/25 14:05:07 INFO util.GSet: Computing capacity for map NameNodeRetryCache</em></li>
<li><em>16/02/25 14:05:07 INFO util.GSet: VM type = 64-bit</em></li>
<li><em>16/02/25 14:05:07 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB</em></li>
<li><em>16/02/25 14:05:07 INFO util.GSet: capacity = 2^15 = 32768 entries</em></li>
<li><em>16/02/25 14:05:08 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1182930464-172.16.101.55-1456380308394</em></li>
<li><em>16/02/25 14:05:08 INFO common.Storage: Storage directory /hadoop/hadoop-2.7.2/data/dfs/name has been successfully formatted.</em></li>
<li><em>16/02/25 14:05:08 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</em></li>
<li><em>16/02/25 14:05:08 INFO util.ExitUtil: Exiting with status 0</em></li>
<li><em>16/02/25 14:05:08 INFO namenode.NameNode: SHUTDOWN_MSG:</em></li>
<li><em>/*<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>***</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></li>
<li><em>SHUTDOWN_MSG: Shutting down NameNode at sht-sgmhadoopnn-01.telenav.cn/172.16.101.55</em></li>
<li><strong>*<strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em>**</em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>/*</li>
</ol>
<p><strong>*c.**</strong>同步<strong><strong>NameNode</strong></strong>元数据***</p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>同步sht-sgmhadoopnn-01 元数据到sht-sgmhadoopnn-02</em></li>
<li><em>主要是：dfs.namenode.name.dir，dfs.namenode.edits.dir还应该确保共享存储目录下(dfs.namenode.shared.edits.dir ) 包含NameNode 所有的元数据。</em></li>
<li><em>[root@sht-sgmhadoopnn-01 hadoop-2.7.2]# pwd</em></li>
<li><em>/hadoop/hadoop-2.7.2</em></li>
<li><em>[root@sht-sgmhadoopnn-01 hadoop-2.7.2]# scp -r data/ root@sht-sgmhadoopnn-02:/hadoop/hadoop-2.7.2</em></li>
<li><em>seen_txid 100% 2 0.0KB/s 00:00</em></li>
<li><em>fsimage_0000000000000000000 100% 351 0.3KB/s 00:00</em></li>
<li><em>fsimage_0000000000000000000.md5 100% 62 0.1KB/s 00:00</em></li>
<li><em>VERSION 100% 205 0.2KB/s 00:00</em></li>
</ol>
<p><strong>*d.**</strong>初始化<strong>*<em>ZFCK</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 bin]# hdfs zkfc -formatZK</em></li>
<li><em>……………..</em></li>
<li><em>……………..</em></li>
<li><em>16/02/25 14:14:41 INFO zookeeper.ZooKeeper: Client environment:user.home=/root</em></li>
<li><em>16/02/25 14:14:41 INFO zookeeper.ZooKeeper: Client environment:user.dir=/hadoop/hadoop-2.7.2/bin</em></li>
<li><em>16/02/25 14:14:41 INFO zookeeper.ZooKeeper: Initiating client  connection, connectString=sht-sgmhadoopdn-01:2181,sht-sgmhadoopdn-02:2181,sht-sgmhadoopdn-03:2181  sessionTimeout=2000  watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@5f4298a5</em></li>
<li><em>16/02/25 14:14:41 INFO zookeeper.ClientCnxn: Opening socket  connection to server  sht-sgmhadoopdn-01.telenav.cn/172.16.101.58:2181. Will not attempt to  authenticate using SASL (unknown error)</em></li>
<li><em>16/02/25 14:14:41 INFO zookeeper.ClientCnxn: Socket connection  established to  sht-sgmhadoopdn-01.telenav.cn/172.16.101.58:2181, initiating session</em></li>
<li><em>16/02/25 14:14:42 INFO zookeeper.ClientCnxn: Session  establishment complete on server  sht-sgmhadoopdn-01.telenav.cn/172.16.101.58:2181, sessionid = 0x15316c965750000, negotiated  timeout = 4000</em></li>
<li><em>16/02/25 14:14:42 INFO ha.ActiveStandbyElector: Session connected.</em></li>
<li><em>16/02/25 14:14:42 INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/mycluster in ZK.</em></li>
<li><em>16/02/25 14:14:42 INFO zookeeper.ClientCnxn: EventThread shut down</em></li>
<li><em>16/02/25 14:14:42 INFO zookeeper.ZooKeeper: Session: 0x15316c965750000 closed</em></li>
</ol>
<p><strong>*e.**</strong>启动<strong>**HDFS</strong> <strong>系统*</strong></p>
<p><em>集群启动,在sht-sgmhadoopnn-01执行start-dfs.sh</em></p>
<p><em>集群关闭,在sht-sgmhadoopnn-01执行stop-dfs.sh</em></p>
<p><em>#####集群启动############</em></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 sbin]# start-dfs.sh</em></li>
<li><em>16/02/25 14:21:42 WARN util.NativeCodeLoader: Unable to load  native-hadoop library for your platform… using builtin-java classes  where applicable</em></li>
<li><em>Starting namenodes on [sht-sgmhadoopnn-01 sht-sgmhadoopnn-02]</em></li>
<li><em>sht-sgmhadoopnn-01: starting namenode, logging to  /hadoop/hadoop-2.7.2/logs/hadoop-root-namenode-sht-sgmhadoopnn-01.telenav.cn.out</em></li>
<li><em>sht-sgmhadoopnn-02: starting namenode, logging to  /hadoop/hadoop-2.7.2/logs/hadoop-root-namenode-sht-sgmhadoopnn-02.telenav.cn.out</em></li>
<li><em>sht-sgmhadoopdn-01: starting datanode, logging to  /hadoop/hadoop-2.7.2/logs/hadoop-root-datanode-sht-sgmhadoopdn-01.telenav.cn.out</em></li>
<li><em>sht-sgmhadoopdn-02: starting datanode, logging to  /hadoop/hadoop-2.7.2/logs/hadoop-root-datanode-sht-sgmhadoopdn-02.telenav.cn.out</em></li>
<li><em>sht-sgmhadoopdn-03: starting datanode, logging to  /hadoop/hadoop-2.7.2/logs/hadoop-root-datanode-sht-sgmhadoopdn-03.telenav.cn.out</em></li>
<li><em>Starting journal nodes [sht-sgmhadoopdn-01 sht-sgmhadoopdn-02 sht-sgmhadoopdn-03]</em></li>
<li><em>sht-sgmhadoopdn-01: journalnode running as process 6348. Stop it first.</em></li>
<li><em>sht-sgmhadoopdn-03: journalnode running as process 16722. Stop it first.</em></li>
<li><em>sht-sgmhadoopdn-02: journalnode running as process 7197. Stop it first.</em></li>
<li><em>16/02/25 14:21:56 WARN util.NativeCodeLoader: Unable to load  native-hadoop library for your platform… using builtin-java classes  where applicable</em></li>
<li><em>Starting ZK Failover Controllers on NN hosts [sht-sgmhadoopnn-01 sht-sgmhadoopnn-02]</em></li>
<li><em>sht-sgmhadoopnn-01: starting zkfc, logging to /hadoop/hadoop-2.7.2/logs/hadoop-root-zkfc-sht-sgmhadoopnn-01.telenav.cn.out</em></li>
<li><em>sht-sgmhadoopnn-02: starting zkfc, logging to /hadoop/hadoop-2.7.2/logs/hadoop-root-zkfc-sht-sgmhadoopnn-02.telenav.cn.out</em></li>
<li><em>You have mail in /var/spool/mail/root</em></li>
</ol>
<p><em>####单进程启动###########</em></p>
<p><strong>*NameNode(sht-sgmhadoopnn-01, sht-sgmhadoopnn-02):*</strong></p>
<p><em>hadoop-daemon.sh start namenode</em></p>
<p><strong>*DataNode(sht-sgmhadoopdn-01, sht-sgmhadoopdn-02, sht-sgmhadoopdn-03):*</strong></p>
<p><em>hadoop-daemon.sh start datanode</em></p>
<p><strong>*JournamNode(sht-sgmhadoopdn-01, sht-sgmhadoopdn-02, sht-sgmhadoopdn-03):*</strong></p>
<p><em>hadoop-daemon.sh start journalnode</em></p>
<p><strong>*ZKFC(sht-sgmhadoopnn-01, sht-sgmhadoopnn-02):*</strong></p>
<p><em>hadoop-daemon.sh start zkfc</em></p>
<p><strong>*f.**</strong>验证<strong>*<em>namenode,datanode,zkfc</em></strong></p>
<p><strong>*1)</strong> <strong>进程*</strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 sbin]# jps</em></li>
<li><em>12712 Jps</em></li>
<li><em>12593 DFSZKFailoverController</em></li>
<li><em>12278 NameNode</em></li>
<li><em>[root@sht-sgmhadoopnn-02 ~]# jps</em></li>
<li><em>29714 NameNode</em></li>
<li><em>29849 DFSZKFailoverController</em></li>
<li><em>30229 Jps</em></li>
<li><em>[root@sht-sgmhadoopdn-01 ~]# jps</em></li>
<li><em>6348 JournalNode</em></li>
<li><em>8775 Jps</em></li>
<li><em>559 QuorumPeerMain</em></li>
<li><em>8509 DataNode</em></li>
<li><em>[root@sht-sgmhadoopdn-02 ~]# jps</em></li>
<li><em>9430 Jps</em></li>
<li><em>9160 DataNode</em></li>
<li><em>7197 JournalNode</em></li>
<li><em>2073 QuorumPeerMain</em></li>
<li><em>[root@sht-sgmhadoopdn-03 ~]# jps</em></li>
<li><em>16722 JournalNode</em></li>
<li><em>17369 Jps</em></li>
<li><em>15519 QuorumPeerMain</em></li>
<li><em>17214 DataNode</em></li>
</ol>
<p><strong>*2)</strong> <strong>页面*</strong></p>
<p><strong>*sht-sgmhadoopnn-01:*</strong></p>
<p><em><a href="http://172.16.101.55:50070/" target="_blank" rel="noopener">http://172.16.101.55:50070/</a></em></p>
<p><strong>*sht-sgmhadoopnn-02:*</strong></p>
<p><em><a href="http://172.16.101.56:50070/" target="_blank" rel="noopener">http://172.16.101.56:50070/</a></em></p>
<p><strong>*g.**</strong>启动<strong><strong>YARN</strong></strong>运算框架***</p>
<p><em>#####集群启动############</em></p>
<p><strong>*1)</strong> <strong>sht-sgmhadoopnn-01**</strong>启动Yarn<strong>*<em>，命令所在目录：$HADOOP_HOME/sbin</em></strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 sbin]# start-yarn.sh</em></li>
<li><em>starting yarn daemons</em></li>
<li><em>starting resourcemanager, logging to /hadoop/hadoop-2.7.2/logs/yarn-root-resourcemanager-sht-sgmhadoopnn-01.telenav.cn.out</em></li>
<li><em>sht-sgmhadoopdn-03: starting nodemanager, logging to  /hadoop/hadoop-2.7.2/logs/yarn-root-nodemanager-sht-sgmhadoopdn-03.telenav.cn.out</em></li>
<li><em>sht-sgmhadoopdn-02: starting nodemanager, logging to  /hadoop/hadoop-2.7.2/logs/yarn-root-nodemanager-sht-sgmhadoopdn-02.telenav.cn.out</em></li>
<li><em>sht-sgmhadoopdn-01: starting nodemanager, logging to  /hadoop/hadoop-2.7.2/logs/yarn-root-nodemanager-sht-sgmhadoopdn-01.telenav.cn.out</em></li>
</ol>
<p><strong>*2)</strong> <strong>sht-sgmhadoopnn-02**</strong>备机启动RM***</p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-02 sbin]# yarn-daemon.sh start resourcemanager</em></li>
<li><em>starting resourcemanager, logging to /hadoop/hadoop-2.7.2/logs/yarn-root-resourcemanager-sht-sgmhadoopnn-02.telenav.cn.out</em></li>
</ol>
<p><em>####单进程启动###########</em></p>
<p><strong>*1)</strong> <strong>ResourceManager(sht-sgmhadoopnn-01, sht-sgmhadoopnn-02)*</strong></p>
<p><em>yarn-daemon.sh start resourcemanager</em></p>
<p><strong>*2)</strong> <strong>NodeManager(sht-sgmhadoopdn-01, sht-sgmhadoopdn-02, sht-sgmhadoopdn-03)*</strong></p>
<p><em>yarn-daemon.sh start nodemanager</em></p>
<p><em>######关闭#############</em></p>
<p><em>[root@sht-sgmhadoopnn-01 sbin]# stop-yarn.sh</em></p>
<p><em>#包含namenode的resourcemanager进程，datanode的nodemanager进程</em></p>
<p><em>[root@sht-sgmhadoopnn-02 sbin]# yarn-daemon.sh stop resourcemanager</em></p>
<p><strong>*h.**</strong>验证<strong>*<em>resourcemanager,nodemanager</em></strong></p>
<p><strong>*1)</strong> <strong>进程*</strong></p>
<p><em>点击(此处)折叠或打开</em></p>
<ol>
<li><em>[root@sht-sgmhadoopnn-01 sbin]# jps</em></li>
<li><em>13611 Jps</em></li>
<li><em>12593 DFSZKFailoverController</em></li>
<li><em>12278 NameNode</em></li>
<li><em>13384 ResourceManager</em></li>
<li><em>[root@sht-sgmhadoopnn-02 sbin]# jps</em></li>
<li><em>32265 ResourceManager</em></li>
<li><em>32304 Jps</em></li>
<li><em>29714 NameNode</em></li>
<li><em>29849 DFSZKFailoverController</em></li>
<li><em>[root@sht-sgmhadoopdn-01 ~]# jps</em></li>
<li><em>6348 JournalNode</em></li>
<li><em>559 QuorumPeerMain</em></li>
<li><em>8509 DataNode</em></li>
<li><em>10286 NodeManager</em></li>
<li><em>10423 Jps</em></li>
<li><em>[root@sht-sgmhadoopdn-02 ~]# jps</em></li>
<li><em>9160 DataNode</em></li>
<li><em>10909 NodeManager</em></li>
<li><em>11937 Jps</em></li>
<li><em>7197 JournalNode</em></li>
<li><em>2073 QuorumPeerMain</em></li>
<li><em>[root@sht-sgmhadoopdn-03 ~]# jps</em></li>
<li><em>18031 Jps</em></li>
<li><em>16722 JournalNode</em></li>
<li><em>17710 NodeManager</em></li>
<li><em>15519 QuorumPeerMain</em></li>
<li><em>17214 DataNode</em></li>
</ol>
<p>2)页面</p>
<p>ResourceManger（Active）：<a href="http://172.16.101.55:8088" target="_blank" rel="noopener">http://172.16.101.55:8088</a></p>
<p>ResourceManger（Standby）：<a href="http://172.16.101.56:8088/cluster/cluster" target="_blank" rel="noopener">http://172.16.101.56:8088/cluster/cluster</a></p>
<p>九.监控集群</p>
<p><em>[root@sht-sgmhadoopnn-01 ~]# hdfs dfsadmin -report</em></p>
<p>十.附件及参考</p>
<p>#<a href="http://archive-primary.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.5.2.tar.gz" target="_blank" rel="noopener">http://archive-primary.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.5.2.tar.gz</a></p>
<p>#<a href="http://archive-primary.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.5.2.tar.gz" target="_blank" rel="noopener">http://archive-primary.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.5.2.tar.gz</a></p>
<p>hadoop :<a href="http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz</a></p>
<p>zookeeper :<a href="http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz</a></p>
<p>参考:</p>
<p><em>Hadoop-2.3.0-cdh5.0.1完全分布式环境搭建(NameNode,ResourceManager HA):</em></p>
<p><a href="http://blog.itpub.net/30089851/viewspace-1987620/" target="_blank" rel="noopener">http://blog.itpub.net/30089851/viewspace-1987620/</a></p>
<p>如何解决这类问题：The string “–” is not permitted within comments:</p>
<p><a href="http://blog.csdn.net/free4294/article/details/38681095" target="_blank" rel="noopener">http://blog.csdn.net/free4294/article/details/38681095</a></p>
<p>SecureCRT连接linux终端中文显示乱码解决办法:</p>
<p><a href="http://www.cnblogs.com/qi09/archive/2013/02/05/2892922.html" target="_blank" rel="noopener">http://www.cnblogs.com/qi09/archive/2013/02/05/2892922.html</a></p>
<p>参照:<a href="http://blog.itpub.net/30089851/viewspace-1987620/" target="_blank" rel="noopener">http://blog.itpub.net/30089851/viewspace-1987620/</a></p>
<p>转自博客：<a href="http://blog.itpub.net/30089851/viewspace-1994585/" target="_blank" rel="noopener">http://blog.itpub.net/30089851/viewspace-1994585/</a></p>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/[转载]YARN的Memory和CPU调优配置详解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/[转载]YARN的Memory和CPU调优配置详解/" itemprop="url">YARN的Memory和CPU调优配置详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T10:55:20+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<p>Hadoop YARN同时支持内存和CPU两种资源的调度，本文介绍如何配置YARN对内存和CPU的使用。</p>
<p>YARN作为一个资源调度器，应该考虑到集群里面每一台机子的计算资源，然后根据application申请的资源进行分配Container。Container是YARN里面资源分配的基本单位，具有一定的内存以及CPU资源。</p>
<p>在YARN集群中，平衡内存、CPU、磁盘的资源的很重要的，根据经验，每两个container使用一块磁盘以及一个CPU核的时候可以使集群的资源得到一个比较好的利用。</p>
<h1 id="内存配置"><a href="#内存配置" class="headerlink" title="内存配置"></a>内存配置</h1><p>关于<em>内存</em>相关的配置可以参考hortonwork公司的文档<a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-11.html" target="_blank" rel="noopener">Determine HDP Memory Configuration Settings</a>来配置你的集群。</p>
<blockquote>
<p>YARN以及MAPREDUCE所有可用的内存资源应该要除去系统运行需要的以及其他的hadoop的一些程序，总共保留的内存=系统内存+HBASE内存。</p>
</blockquote>
<p>可以参考下面的表格确定应该保留的内存：</p>
<table>
<thead>
<tr>
<th>每台机子内存</th>
<th>系统需要的内存</th>
<th>HBase需要的内存</th>
</tr>
</thead>
<tbody>
<tr>
<td>4GB</td>
<td>1GB</td>
<td>1GB</td>
</tr>
<tr>
<td>8GB</td>
<td>2GB</td>
<td>1GB</td>
</tr>
<tr>
<td>16GB</td>
<td>2GB</td>
<td>2GB</td>
</tr>
<tr>
<td>24GB</td>
<td>4GB</td>
<td>4GB</td>
</tr>
<tr>
<td>48GB</td>
<td>6GB</td>
<td>8GB</td>
</tr>
<tr>
<td>64GB</td>
<td>8GB</td>
<td>8GB</td>
</tr>
<tr>
<td>72GB</td>
<td>8GB</td>
<td>8GB</td>
</tr>
<tr>
<td>96GB</td>
<td>12GB</td>
<td>16GB</td>
</tr>
<tr>
<td>128GB</td>
<td>24GB</td>
<td>24GB</td>
</tr>
<tr>
<td>255GB</td>
<td>32GB</td>
<td>32GB</td>
</tr>
<tr>
<td>512GB</td>
<td>64GB</td>
<td>64GB</td>
</tr>
</tbody>
</table>
<p>计算每台机子最多可以拥有多少个container，可以使用下面的公式:</p>
<p>containers = min (2<em>CORES, 1.8</em>DISKS, (Total available RAM) / MIN_CONTAINER_SIZE)</p>
<p>说明：</p>
<ul>
<li>CORES为机器CPU核数</li>
<li>DISKS为机器上挂载的磁盘个数</li>
<li>Total available RAM为机器总内存</li>
<li>MIN_CONTAINER_SIZE是指container最小的容量大小，这需要根据具体情况去设置，可以参考下面的表格：</li>
</ul>
<table>
<thead>
<tr>
<th>每台机子可用的RAM</th>
<th>container最小值</th>
</tr>
</thead>
<tbody>
<tr>
<td>小于4GB</td>
<td>256MB</td>
</tr>
<tr>
<td>4GB到8GB之间</td>
<td>512MB</td>
</tr>
<tr>
<td>8GB到24GB之间</td>
<td>1024MB</td>
</tr>
<tr>
<td>大于24GB</td>
<td>2048MB</td>
</tr>
</tbody>
</table>
<p>每个container的平均使用内存大小计算方式为：</p>
<p>RAM-per-container = max(MIN_CONTAINER_SIZE, (Total Available RAM) / containers))</p>
<p>通过上面的计算，YARN以及MAPREDUCE可以这样配置：</p>
<table>
<thead>
<tr>
<th>配置文件</th>
<th>配置设置</th>
<th>默认值</th>
<th>计算值</th>
</tr>
</thead>
<tbody>
<tr>
<td>yarn-site.xml</td>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>8192 MB</td>
<td>= containers * RAM-per-container</td>
</tr>
<tr>
<td>yarn-site.xml</td>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>1024MB</td>
<td>= RAM-per-container</td>
</tr>
<tr>
<td>yarn-site.xml</td>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>8192 MB</td>
<td>= containers * RAM-per-container</td>
</tr>
<tr>
<td>yarn-site.xml (check)</td>
<td>yarn.app.mapreduce.am.resource.mb</td>
<td>1536 MB</td>
<td>= 2 * RAM-per-container</td>
</tr>
<tr>
<td>yarn-site.xml (check)</td>
<td>yarn.app.mapreduce.am.command-opts</td>
<td>-Xmx1024m</td>
<td>= 0.8 <em> 2 </em> RAM-per-container</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.map.memory.mb</td>
<td>1024 MB</td>
<td>= RAM-per-container</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.reduce.memory.mb</td>
<td>1024 MB</td>
<td>= 2 * RAM-per-container</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.map.java.opts</td>
<td></td>
<td>= 0.8 * RAM-per-container</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.reduce.java.opts</td>
<td></td>
<td>= 0.8 <em> 2 </em> RAM-per-container</td>
</tr>
</tbody>
</table>
<p>举个例子：对于128G内存、32核CPU的机器，挂载了7个磁盘，根据上面的说明，系统保留内存为24G，不适应HBase情况下，系统剩余可用内存为104G，计算containers值如下：</p>
<p>containers = min (2<em>32, 1.8</em> 7 , (128-24)/2) = min (64, 12.6 , 51) = 13</p>
<p>计算RAM-per-container值如下：</p>
<p>RAM-per-container = max (2, (124-24)/13) = max (2, 8) = 8</p>
<p>你也可以使用脚本<a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-9.html" target="_blank" rel="noopener">yarn-utils.py</a>来计算上面的值：</p>
<p>点击(此处)折叠或打开</p>
<ol>
<li>#!/usr/bin/env python</li>
<li>import optparse</li>
<li>from pprint import pprint</li>
<li>import logging</li>
<li>import sys</li>
<li>import math</li>
<li>import ast</li>
<li></li>
<li>‘’’ Reserved for OS + DN + NM, Map: Memory =&gt; Reservation ‘’’</li>
<li>reservedStack = { 4:1, 8:2, 16:2, 24:4, 48:6, 64:8, 72:8, 96:12, </li>
<li>​                   128:24, 256:32, 512:64}</li>
<li>‘’’ Reserved for HBase. Map: Memory =&gt; Reservation ‘’’</li>
<li></li>
<li>reservedHBase = {4:1, 8:1, 16:2, 24:4, 48:8, 64:8, 72:8, 96:16, </li>
<li>​                   128:24, 256:32, 512:64}</li>
<li>GB = 1024</li>
<li></li>
<li>def getMinContainerSize(memory):</li>
<li>if (memory &lt;= 4):</li>
<li>​    return 256</li>
<li>elif (memory &lt;= 8):</li>
<li>​    return 512</li>
<li>elif (memory &lt;= 24):</li>
<li>​    return 1024</li>
<li>else:</li>
<li>​    return 2048</li>
<li>pass</li>
<li></li>
<li>def getReservedStackMemory(memory):</li>
<li>if (reservedStack.has_key(memory)):</li>
<li>​    return reservedStack[memory]</li>
<li>if (memory &lt;= 4):</li>
<li>​    ret = 1</li>
<li>elif (memory &gt;= 512):</li>
<li>​    ret = 64</li>
<li>else:</li>
<li>​    ret = 1</li>
<li>return ret</li>
<li></li>
<li>def getReservedHBaseMem(memory):</li>
<li>if (reservedHBase.has_key(memory)):</li>
<li>​    return reservedHBase[memory]</li>
<li>if (memory &lt;= 4):</li>
<li>​    ret = 1</li>
<li>elif (memory &gt;= 512):</li>
<li>​    ret = 64</li>
<li>else:</li>
<li>​    ret = 2</li>
<li>return ret</li>
<li>​                    </li>
<li>def main():</li>
<li>log = logging.getLogger(<strong>name</strong>)</li>
<li>out_hdlr = logging.StreamHandler(sys.stdout)</li>
<li>out_hdlr.setFormatter(logging.Formatter(‘ %(message)s’))</li>
<li>out_hdlr.setLevel(logging.INFO)</li>
<li>log.addHandler(out_hdlr)</li>
<li>log.setLevel(logging.INFO)</li>
<li>parser = optparse.OptionParser()</li>
<li>memory = 0</li>
<li>cores = 0</li>
<li>disks = 0</li>
<li>hbaseEnabled = True</li>
<li>parser.add_option(‘-c’, ‘–cores’, default = 16,</li>
<li>​                     help = ‘Number of cores on each host’)</li>
<li>parser.add_option(‘-m’, ‘–memory’, default = 64, </li>
<li>​                    help = ‘Amount of Memory on each host in GB’)</li>
<li>parser.add_option(‘-d’, ‘–disks’, default = 4, </li>
<li>​                    help = ‘Number of disks on each host’)</li>
<li>parser.add_option(‘-k’, ‘–hbase’, default = “True”,</li>
<li>​                    help = ‘True if HBase is installed, False is not’)</li>
<li>(options, args) = parser.parse_args()</li>
<li></li>
<li>cores = int (options.cores)</li>
<li>memory = int (options.memory)</li>
<li>disks = int (options.disks)</li>
<li>hbaseEnabled = ast.literal_eval(options.hbase)</li>
<li></li>
<li>log.info(“Using cores=” + str(cores) + “ memory=” + str(memory) + “GB” +</li>
<li>​            “ disks=” + str(disks) + “ hbase=” + str(hbaseEnabled))</li>
<li>minContainerSize = getMinContainerSize(memory)</li>
<li>reservedStackMemory = getReservedStackMemory(memory)</li>
<li>reservedHBaseMemory = 0</li>
<li>if (hbaseEnabled):</li>
<li>​    reservedHBaseMemory = getReservedHBaseMem(memory)</li>
<li>reservedMem = reservedStackMemory + reservedHBaseMemory</li>
<li>usableMem = memory - reservedMem</li>
<li>memory -= (reservedMem)</li>
<li>if (memory &lt; 2):</li>
<li>​    memory = 2</li>
<li>​    reservedMem = max(0, memory - reservedMem)</li>
<li>​    </li>
<li>memory *= GB</li>
<li></li>
<li>containers = int (min(2 * cores,</li>
<li>​                         min(math.ceil(1.8 * float(disks)),</li>
<li>​                              memory/minContainerSize)))</li>
<li>if (containers &lt;= 2):</li>
<li>​    containers = 3</li>
<li></li>
<li>log.info(“Profile: cores=” + str(cores) + “ memory=” + str(memory) + “MB”</li>
<li>​           + “ reserved=” + str(reservedMem) + “GB” + “ usableMem=”</li>
<li>​           + str(usableMem) + “GB” + “ disks=” + str(disks))</li>
<li>​    </li>
<li>container_ram = abs(memory/containers)</li>
<li>if (container_ram &gt; GB):</li>
<li>​    container_ram = int(math.floor(container_ram / 512)) * 512</li>
<li>log.info(“Num Container=” + str(containers))</li>
<li>log.info(“Container Ram=” + str(container_ram) + “MB”)</li>
<li>log.info(“Used Ram=” + str(int (containers*container_ram/float(GB))) + “GB”)</li>
<li>log.info(“Unused Ram=” + str(reservedMem) + “GB”)</li>
<li>log.info(“yarn.scheduler.minimum-allocation-mb=” + str(container_ram))</li>
<li>log.info(“yarn.scheduler.maximum-allocation-mb=” + str(containers*container_ram))</li>
<li>log.info(“yarn.nodemanager.resource.memory-mb=” + str(containers*container_ram))</li>
<li>map_memory = container_ram</li>
<li>reduce_memory = 2*container_ram if (container_ram &lt;= 2048) else container_ram</li>
<li>am_memory = max(map_memory, reduce_memory)</li>
<li>log.info(“mapreduce.map.memory.mb=” + str(map_memory))</li>
<li>log.info(“mapreduce.map.java.opts=-Xmx” + str(int(0.8 * map_memory)) +”m”)</li>
<li>log.info(“mapreduce.reduce.memory.mb=” + str(reduce_memory))</li>
<li>log.info(“mapreduce.reduce.java.opts=-Xmx” + str(int(0.8 * reduce_memory)) + “m”)</li>
<li>log.info(“yarn.app.mapreduce.am.resource.mb=” + str(am_memory))</li>
<li>log.info(“yarn.app.mapreduce.am.command-opts=-Xmx” + str(int(0.8*am_memory)) + “m”)</li>
<li>log.info(“mapreduce.task.io.sort.mb=” + str(int(0.4 * map_memory)))</li>
<li>pass</li>
<li></li>
<li>if <strong>name</strong> == ‘<strong>main</strong>‘:</li>
<li>try:</li>
<li>​    main()</li>
<li>except(KeyboardInterrupt, EOFError):</li>
<li>​    print(“\nAborting … Keyboard Interrupt.”)</li>
<li>​    sys.exit(1)</li>
</ol>
<p>执行下面命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python yarn-utils.py -c 32 -m 128 -d 7 -k False</span><br></pre></td></tr></table></figure>
<p>返回结果如下：</p>
<p>点击(此处)折叠或打开</p>
<ol>
<li>Using cores=32 memory=128GB disks=7 hbase=False</li>
<li>Profile: cores=32 memory=106496MB reserved=24GB usableMem=104GB disks=7</li>
<li>Num Container=13</li>
<li>Container Ram=8192MB</li>
<li>Used Ram=104GB</li>
<li>Unused Ram=24GB</li>
<li>yarn.scheduler.minimum-allocation-mb=8192</li>
<li>yarn.scheduler.maximum-allocation-mb=106496</li>
<li>yarn.nodemanager.resource.memory-mb=106496</li>
<li>mapreduce.map.memory.mb=8192</li>
<li>mapreduce.map.java.opts=-Xmx6553m</li>
<li>mapreduce.reduce.memory.mb=8192</li>
<li>mapreduce.reduce.java.opts=-Xmx6553m</li>
<li>yarn.app.mapreduce.am.resource.mb=8192</li>
<li>yarn.app.mapreduce.am.command-opts=-Xmx6553m</li>
<li>mapreduce.task.io.sort.mb=3276</li>
</ol>
<p>这样的话，每个container内存为8G，似乎有点多，我更愿意根据集群使用情况任务将其调整为2G内存，则集群中下面的参数配置值如下：</p>
<table>
<thead>
<tr>
<th>配置文件</th>
<th>配置设置</th>
<th>计算值</th>
</tr>
</thead>
<tbody>
<tr>
<td>yarn-site.xml</td>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>= 52 * 2 =104 G</td>
</tr>
<tr>
<td>yarn-site.xml</td>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>= 2G</td>
</tr>
<tr>
<td>yarn-site.xml</td>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>= 52 * 2 = 104G</td>
</tr>
<tr>
<td>yarn-site.xml (check)</td>
<td>yarn.app.mapreduce.am.resource.mb</td>
<td>= 2 * 2=4G</td>
</tr>
<tr>
<td>yarn-site.xml (check)</td>
<td>yarn.app.mapreduce.am.command-opts</td>
<td>= 0.8 <em> 2 </em> 2=3.2G</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.map.memory.mb</td>
<td>= 2G</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.reduce.memory.mb</td>
<td>= 2 * 2=4G</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.map.java.opts</td>
<td>= 0.8 * 2=1.6G</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>mapreduce.reduce.java.opts</td>
<td>= 0.8 <em> 2 </em> 2=3.2G</td>
</tr>
</tbody>
</table>
<p>对应的xml配置为：</p>
<p>点击(此处)折叠或打开</p>
<ol>
<li><property></property></li>
<li>​      <name>yarn.nodemanager.resource.memory-mb</name></li>
<li>​      <value>106496</value></li>
<li></li>
<li><property></property></li>
<li>​      <name>yarn.scheduler.minimum-allocation-mb</name></li>
<li>​      <value>2048</value></li>
<li></li>
<li><property></property></li>
<li>​      <name>yarn.scheduler.maximum-allocation-mb</name></li>
<li>​      <value>106496</value></li>
<li></li>
<li><property></property></li>
<li>​      <name>yarn.app.mapreduce.am.resource.mb</name></li>
<li>​      <value>4096</value></li>
<li></li>
<li><property></property></li>
<li>​      <name>yarn.app.mapreduce.am.command-opts</name></li>
<li>​      <value>-Xmx3276m</value></li>
<li></li>
</ol>
<p>另外，还有一下几个参数：</p>
<ul>
<li>yarn.nodemanager.vmem-pmem-ratio：任务每使用1MB物理内存，最多可使用虚拟内存量，默认是2.1。</li>
<li>yarn.nodemanager.pmem-check-enabled：是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true。</li>
<li>yarn.nodemanager.vmem-pmem-ratio：是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true。</li>
</ul>
<p>第一个参数的意思是当一个map任务总共分配的物理内存为2G的时候，该任务的container最多内分配的堆内存为1.6G，可以分配的虚拟内存上限为2*2.1=4.2G。另外，照这样算下去，每个节点上YARN可以启动的Map数为104/2=52个。</p>
<h1 id="CPU配置"><a href="#CPU配置" class="headerlink" title="CPU配置"></a>CPU配置</h1><p>YARN中目前的CPU被划分成虚拟CPU（CPU  virtual  Core），这里的虚拟CPU是YARN自己引入的概念，初衷是，考虑到不同节点的CPU性能可能不同，每个CPU具有的计算能力也是不一样的，比如某个物理CPU的计算能力可能是另外一个物理CPU的2倍，这时候，你可以通过为第一个物理CPU多配置几个虚拟CPU弥补这种差异。用户提交作业时，可以指定每个任务需要的虚拟CPU个数。</p>
<p>在YARN中，CPU相关配置参数如下：</p>
<ul>
<li>yarn.nodemanager.resource.cpu-vcores：表示该节点上YARN可使用的虚拟CPU个数，默认是8，注意，目前推荐将该值设值为与物理CPU核数数目相同。如果你的节点CPU核数不够8个，则需要调减小这个值，而YARN不会智能的探测节点的物理CPU总数。</li>
<li>yarn.scheduler.minimum-allocation-vcores：单个任务可申请的最小虚拟CPU个数，默认是1，如果一个任务申请的CPU个数少于该数，则该对应的值改为这个数。</li>
<li>yarn.scheduler.maximum-allocation-vcores：单个任务可申请的最多虚拟CPU个数，默认是32。</li>
</ul>
<p>对于一个CPU核数较多的集群来说，上面的默认配置显然是不合适的，在我的测试集群中，4个节点每个机器CPU核数为31，留一个给操作系统，可以配置为：</p>
<p>点击(此处)折叠或打开</p>
<ol>
<li><property></property></li>
<li>​      <name>yarn.nodemanager.resource.cpu-vcores</name></li>
<li>​      <value>31</value></li>
<li></li>
<li><property></property></li>
<li>​      <name>yarn.scheduler.maximum-allocation-vcores</name></li>
<li>​      <value>124</value></li>
<li></li>
</ol>
<p> 转自博客:<a href="http://blog.javachen.com/2015/06/05/yarn-memory-and-cpu-configuration.html?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="noopener">http://blog.javachen.com/2015/06/05/yarn-memory-and-cpu-configuration.html?utm_source=tuicool&amp;utm_medium=referral</a></p>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/Hadoop生态系统官网、下载地址、文档/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/Hadoop生态系统官网、下载地址、文档/" itemprop="url">Hadoop生态系统官网、下载地址、文档</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T10:51:12+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  245
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<p>Apache版本：</p>
<p>Hadoop官网：<a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a><br>Hadoop下载：<a href="http://mirror.bit.edu.cn/apache/hadoop/common/" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/hadoop/common/</a></p>
<p>Hadoop历史版本下载：<a href="http://archive.apache.org/dist/hadoop/core/" target="_blank" rel="noopener">http://archive.apache.org/dist/hadoop/core/</a><br>Hadoop文档：<a href="http://hadoop.apache.org/docs/" target="_blank" rel="noopener">http://hadoop.apache.org/docs/</a></p>
<p>Hive官网：<a href="http://hive.apache.org/" target="_blank" rel="noopener">http://hive.apache.org/</a><br>Hive下载：<a href="http://mirror.bit.edu.cn/apache/hive/" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/hive/</a></p>
<p>Hive历史版本下载：<a href="http://archive.apache.org/dist/hive/" target="_blank" rel="noopener">http://archive.apache.org/dist/hive/</a><br>Hive文档：<a href="https://cwiki.apache.org/confluence/display/Hive" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive</a></p>
<p>HBase官网：<a href="http://hbase.apache.org/" target="_blank" rel="noopener">http://hbase.apache.org/</a><br>HBase下载：<a href="http://mirrors.sonic.net/apache/hbase/" target="_blank" rel="noopener">http://mirrors.sonic.net/apache/hbase/</a></p>
<p>HBase历史版本下载：<a href="http://archive.apache.org/dist/hbase/" target="_blank" rel="noopener">http://archive.apache.org/dist/hbase/</a><br>HBase文档：<a href="http://hbase.apache.org/book.html" target="_blank" rel="noopener">http://hbase.apache.org/book.html</a><br>HBase中文文档：<a href="http://abloz.com/hbase/book.html" target="_blank" rel="noopener">http://abloz.com/hbase/book.html</a></p>
<p>Spark官网：<a href="http://spark.apache.org/" target="_blank" rel="noopener">http://spark.apache.org/</a><br>Spark下载：<a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">http://spark.apache.org/downloads.html</a><br>Spark文档：<a href="http://spark.apache.org/docs/latest/" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/</a></p>
<p>Zookeeper官网：<a href="http://zookeeper.apache.org/" target="_blank" rel="noopener">http://zookeeper.apache.org/</a><br>Zookeeper下载：<a href="http://zookeeper.apache.org/releases.html#download" target="_blank" rel="noopener">http://zookeeper.apache.org/releases.html#download</a></p>
<p>Flume官网：<a href="http://flume.apache.org/" target="_blank" rel="noopener">http://flume.apache.org/</a><br>Flume下载：<a href="http://flume.apache.org/download.html" target="_blank" rel="noopener">http://flume.apache.org/download.html</a><br>Flume文档：<a href="http://flume.apache.org/documentation.html" target="_blank" rel="noopener">http://flume.apache.org/documentation.html</a></p>
<p>Mahout官网：<a href="http://mahout.apache.org/" target="_blank" rel="noopener">http://mahout.apache.org/</a><br>Mahout下载：<a href="http://mahout.apache.org/general/downloads.html" target="_blank" rel="noopener">http://mahout.apache.org/general/downloads.html</a></p>
<p>Tez官网：<a href="http://tez.apache.org/" target="_blank" rel="noopener">http://tez.apache.org/</a></p>
<p>cdh5版本：<br>下载地址：<a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/</a></p>
<p>文档地址：<a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/</a></p>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/HDFS命令操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/HDFS命令操作/" itemprop="url">HDFS命令操作</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T10:41:38+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<p><strong>命令基本格式:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cmd &lt; args &gt;</span><br></pre></td></tr></table></figure>
<p><strong>1.ls</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls  /</span><br></pre></td></tr></table></figure>
<p>列出hdfs文件系统根目录下的目录和文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls -R /</span><br></pre></td></tr></table></figure>
<p>列出hdfs文件系统所有的目录和文件</p>
<p><strong>2.put</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put &lt; local file &gt; &lt; hdfs file &gt;</span><br></pre></td></tr></table></figure>
<p>hdfs file的父目录一定要存在，否则命令不会执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put  &lt; local file or dir &gt;...&lt; hdfs dir &gt;</span><br></pre></td></tr></table></figure>
<p>hdfs dir 一定要存在，否则命令不会执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put - &lt; hdsf  file&gt;</span><br></pre></td></tr></table></figure>
<p>从键盘读取输入到hdfs file中，按Ctrl+D结束输入，hdfs file不能存在，否则命令不会执行</p>
<p>2.1.moveFromLocal</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -moveFromLocal  &lt; local src &gt; ... &lt; hdfs dst &gt;</span><br></pre></td></tr></table></figure>
<p>与put相类似，命令执行后源文件 local src 被删除，也可以从从键盘读取输入到hdfs file中</p>
<p>2.2.copyFromLocal</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal  &lt; local src &gt; ... &lt; hdfs dst &gt;</span><br></pre></td></tr></table></figure>
<p>与put相类似，也可以从从键盘读取输入到hdfs file中</p>
<p><strong>3.get</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get &lt; hdfs file &gt; &lt; local file or dir&gt;</span><br></pre></td></tr></table></figure>
<p>local file不能和 hdfs file名字不能相同，否则会提示文件已存在，没有重名的文件会复制到本地</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get &lt; hdfs file or dir &gt; ... &lt; local  dir &gt;</span><br></pre></td></tr></table></figure>
<p>拷贝多个文件或目录到本地时，本地要为文件夹路径<br>注意：如果用户不是root， local 路径要为用户文件夹下的路径，否则会出现权限问题，</p>
<p>3.1.moveToLocal</p>
<p>3.2.copyToLocal</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal &lt; local src &gt; ... &lt; hdfs dst &gt;</span><br></pre></td></tr></table></figure>
<p>与get相类似</p>
<p><strong>4.rm</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm &lt; hdfs file &gt; ...</span><br><span class="line">hadoop fs -rm -r &lt; hdfs dir&gt;...</span><br><span class="line"></span><br><span class="line">每次可以删除多个文件或目录</span><br></pre></td></tr></table></figure>
<p><strong>5.mkdir</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir &lt; hdfs path&gt;</span><br></pre></td></tr></table></figure>
<p>只能一级一级的建目录，父目录不存在的话使用这个命令会报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p &lt; hdfs path&gt;</span><br></pre></td></tr></table></figure>
<p>所创建的目录如果父目录不存在就创建该父目录</p>
<p><strong>6.getmerge</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge &lt; hdfs dir &gt;  &lt; local file &gt;</span><br></pre></td></tr></table></figure>
<p>将hdfs指定目录下所有文件排序后合并到local指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge -nl  &lt; hdfs dir &gt;  &lt; local file &gt;</span><br></pre></td></tr></table></figure>
<p>加上nl后，合并到local file中的hdfs文件之间会空出一行</p>
<p><strong>7.cp</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp  &lt; hdfs file &gt;  &lt; hdfs file &gt;</span><br></pre></td></tr></table></figure>
<p>目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件还存在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp &lt; hdfs file or dir &gt;... &lt; hdfs dir &gt;</span><br></pre></td></tr></table></figure>
<p>目标文件夹要存在，否则命令不能执行</p>
<p><strong>8.mv</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv &lt; hdfs file &gt;  &lt; hdfs file &gt;</span><br></pre></td></tr></table></figure>
<p>目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件不存在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv  &lt; hdfs file or dir &gt;...  &lt; hdfs dir &gt;</span><br></pre></td></tr></table></figure>
<p>源路径有多个时，目标路径必须为目录，且必须存在。<br>注意：跨文件系统的移动（local到hdfs或者反过来）都是不允许的</p>
<p><strong>9.count</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -count &lt; hdfs path &gt;</span><br></pre></td></tr></table></figure>
<p>统计hdfs对应路径下的目录个数，文件个数，文件总计大小 显示为目录个数，文件个数，文件总计大小，输入路径</p>
<p><strong>10.du</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du &lt; hdsf path&gt;</span><br></pre></td></tr></table></figure>
<p>显示hdfs对应路径下每个文件夹和文件的大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du -s &lt; hdsf path&gt;</span><br></pre></td></tr></table></figure>
<p>显示hdfs对应路径下所有文件和的大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du - h &lt; hdsf path&gt;</span><br></pre></td></tr></table></figure>
<p>显示hdfs对应路径下每个文件夹和文件的大小,文件的大小用方便阅读的形式表示，例如用64M代替67108864</p>
<p><strong>11.text</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -text &lt; hdsf file&gt;</span><br></pre></td></tr></table></figure>
<p>将文本文件或某些格式的非文本文件通过文本格式输出</p>
<p><strong>12.setrep</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep -R 3 &lt; hdfs path &gt;</span><br></pre></td></tr></table></figure>
<p>改变一个文件在hdfs中的副本个数，上述命令中数字3为所设置的副本个数，-R选项可以对一个人目录下的所有目录+文件递归执行改变副本个数的操作</p>
<p><strong>13.stat</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdoop fs -stat [format] &lt; hdfs path &gt;</span><br></pre></td></tr></table></figure>
<p>返回对应路径的状态信息<br>[format]可选参数有：%b（文件大小），%o（Block大小），%n（文件名），%r（副本个数），%y（最后一次修改日期和时间）<br>可以这样书写hadoop fs -stat %b%o%n &lt; hdfs path &gt;，不过不建议，这样每个字符输出的结果不是太容易分清楚</p>
<p><strong>14.tail</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -tail &lt; hdfs file &gt;</span><br></pre></td></tr></table></figure>
<p>在标准输出中显示文件末尾的1KB数据</p>
<p><strong>15.archive</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop archive -archiveName name.har -p &lt; hdfs parent dir &gt; &lt; src &gt;* &lt; hdfs dst &gt;</span><br></pre></td></tr></table></figure>
<p>命令中参数name：压缩文件名，自己任意取；&lt; hdfs parent dir &gt; ：压缩文件所在的父目录；&lt; src &gt;：要压缩的文件名；&lt; hdfs dst &gt;：压缩文件存放路径<br>*示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop archive -archiveName hadoop.har -p /user 1.txt 2.txt /des</span><br></pre></td></tr></table></figure>
<p>示例中将hdfs中/user目录下的文件1.txt，2.txt压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下，如果1.txt，2.txt不写就是将/user目录下所有的目录和文件压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下<br>显示har的内容可以用如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /des/hadoop.jar</span><br></pre></td></tr></table></figure>
<p>显示har压缩的是那些文件可以用如下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls -R har:///des/hadoop.har</span><br></pre></td></tr></table></figure>
<p>注意：har文件不能进行二次压缩。如果想给.har加文件，只能找到原来的文件，重新创建一个。har文件中原来文件的数据并没有变化，har文件真正的作用是减少NameNode和DataNode过多的空间浪费。</p>
<p><strong>16.balancer</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs balancer</span><br></pre></td></tr></table></figure>
<p>如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程</p>
<p><strong>17.dfsadmin</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -help</span><br></pre></td></tr></table></figure>
<p>管理员可以通过dfsadmin管理HDFS，用法可以通过上述命令查看</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -report</span><br></pre></td></tr></table></figure>
<p>显示文件系统的基本数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -safemode &lt; enter | leave | get | wait &gt;</span><br></pre></td></tr></table></figure>
<p>enter：进入安全模式；leave：离开安全模式；get：获知是否开启安全模式； wait：等待离开安全模式</p>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/3.Hadoop伪分布式（MapReduce+YARN）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/3.Hadoop伪分布式（MapReduce+YARN）/" itemprop="url">Hadoop部署MapReduce+YARN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T10:35:33+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  800
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="1-yarn部署："><a href="#1-yarn部署：" class="headerlink" title="1.yarn部署："></a><strong>1.yarn部署：</strong></h2><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">	 <span class="type">MapReduce</span>: 计算的 是jar包提交的<span class="type">Yarn</span>上  本身不需要部署</span><br><span class="line">	 <span class="type">Yarn</span>: 资源和作业调度 是需要部署的</span><br><span class="line">	 因为：<span class="type">MapReduce</span> on <span class="type">Yarn</span>（mapreduce是运行在yarn上）</span><br><span class="line">	 </span><br><span class="line"></span><br><span class="line">&gt; <span class="type">Configure</span> parameters <span class="keyword">as</span> follows:（配置信息步骤）</span><br><span class="line">&gt; </span><br><span class="line"><span class="title">etc</span>/hadoop/mapred-site.xml:</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="title">etc</span>/hadoop/yarn-site.xml:</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h2 id="2-sbin-start-yarn-sh-启动yarn："><a href="#2-sbin-start-yarn-sh-启动yarn：" class="headerlink" title="2.sbin/start-yarn.sh 启动yarn："></a><strong>2.sbin/start-yarn.sh 启动yarn：</strong></h2><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop002 hadoop<span class="number">-2.6</span><span class="number">.0</span>-cdh5<span class="number">.7</span><span class="number">.0</span>]$ jps</span><br><span class="line"><span class="number">4001</span> <span class="type">NodeManager</span></span><br><span class="line"><span class="number">3254</span> <span class="type">SecondaryNameNode</span></span><br><span class="line"><span class="number">3910</span> <span class="type">ResourceManager</span></span><br><span class="line"><span class="number">3563</span> <span class="type">NameNode</span></span><br><span class="line"><span class="number">4317</span> <span class="type">Jps</span></span><br><span class="line"><span class="number">3087</span> <span class="type">DataNode</span></span><br><span class="line"></span><br><span class="line"><span class="type">ResourceManager</span> daemon  （老大 资源管理者）</span><br><span class="line"><span class="type">NodeManager</span> daemon      （小弟 节点管理者）</span><br><span class="line">$ sbin/start-yarn.sh</span><br><span class="line">Browse the web interface for the ResourceManager; by default it is available at:</span><br><span class="line"><span class="type">ResourceManager</span> - http://localhost:<span class="number">8088</span>/</span><br><span class="line">这时我们可以去看一下yarn的web界面：http://localhost:<span class="number">8088</span>/</span><br></pre></td></tr></table></figure>
<h2 id="3-怎样查看错误："><a href="#3-怎样查看错误：" class="headerlink" title="3.怎样查看错误："></a><strong>3.怎样查看错误：</strong></h2><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> 在生产中我们要会查看日志，在日志中查找错误</span><br><span class="line"> logs/目录下：</span><br><span class="line"> hadoop-hadoop-datanode-hadoop002.log</span><br><span class="line"> 对应的名字分别是：</span><br><span class="line"> hadoop-用户-进程名称-机器名称</span><br><span class="line"> 一共有三种方法可以去查看：</span><br><span class="line"><span class="number">01</span> vi :/搜索 <span class="type">ERROR</span></span><br><span class="line"><span class="number">02</span> tail <span class="number">-200</span>f xxx.log（倒着查看log中的后<span class="number">200</span>行日志）  另外窗口重启进程 为了再现这个错误</span><br><span class="line"></span><br><span class="line"><span class="number">03</span> rz上传到windows editplus去定位查看 备份 （一般对于生产中日志比较大的文件）</span><br></pre></td></tr></table></figure>
<h2 id="4-运行mr"><a href="#4-运行mr" class="headerlink" title="4.运行mr"></a><strong>4.运行mr</strong></h2><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">	 map 	（映射）</span><br><span class="line">	 reduce （规约）</span><br><span class="line">	 </span><br><span class="line"></span><br><span class="line">&gt; 	词频统计</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop002 hadoop<span class="number">-2.6</span><span class="number">.0</span>-cdh5<span class="number">.7</span><span class="number">.0</span>]$ vi a.log（先编辑一个文件保存）</span><br><span class="line"><span class="title">ruoze</span></span><br><span class="line"><span class="title">jepson</span></span><br><span class="line"><span class="title">www</span>.ruozedata.com</span><br><span class="line"><span class="title">dashu</span></span><br><span class="line"><span class="title">adai</span></span><br><span class="line"><span class="title">fanren</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="title">a</span></span><br><span class="line"><span class="title">b</span></span><br><span class="line"><span class="title">c</span></span><br><span class="line"><span class="title">a</span> b c ruoze jepon</span><br><span class="line">[hadoop@hadoop002 hadoop<span class="number">-2.6</span><span class="number">.0</span>-cdh5<span class="number">.7</span><span class="number">.0</span>]$ vi b.txt（再编辑一个文件保存）</span><br><span class="line"><span class="title">a</span> b d e f ruoze</span><br><span class="line"><span class="number">1</span> <span class="number">1</span> <span class="number">3</span> <span class="number">5</span></span><br><span class="line"></span><br><span class="line">[hadoop@hadoop002 hadoop<span class="number">-2.6</span><span class="number">.0</span>-cdh5<span class="number">.7</span><span class="number">.0</span>]$ hdfs dfs  -mkdir -p /wordcount/input （在hdfs家目录下创建一个级联文件及）</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop002 hadoop<span class="number">-2.6</span><span class="number">.0</span>-cdh5<span class="number">.7</span><span class="number">.0</span>]$ hdfs dfs -put a.log /wordcount/input</span><br><span class="line">[hadoop@hadoop002 hadoop<span class="number">-2.6</span><span class="number">.0</span>-cdh5<span class="number">.7</span><span class="number">.0</span>]$ hdfs dfs -put b.txt /wordcount/input（将a.log和b.text文件上传到文件夹下）</span><br><span class="line">[hadoop@hadoop002 hadoop<span class="number">-2.6</span><span class="number">.0</span>-cdh5<span class="number">.7</span><span class="number">.0</span>]$ hdfs dfs -ls /wordcount/input/（查看一下文件夹下的内容）</span><br><span class="line"><span class="type">Found</span> <span class="number">2</span> items</span><br><span class="line">-rw-r<span class="comment">--r--   1 hadoop supergroup         76 2019-02-16 21:59 /wordcount/input/a.log</span></span><br><span class="line">-rw-r<span class="comment">--r--   1 hadoop supergroup         24 2019-02-16 21:59 /wordcount/input/b.txt</span></span><br></pre></td></tr></table></figure>
<p> 这里我们做一个列子，mapreduce中会给出 examples，<br>​     我们可以通过：find ./ -name ‘<em>example</em>.jar’找到这个jar包：<br>​     ./share/hadoop/mapreduce2/hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar<br>​     虽然我们不知道命令时什么，但是我们可以查看命令帮助：<br>​     hadoop回车，向下翻看，会发现有一个命令是 jar <jar><br>​     <img src="https://img-blog.csdnimg.cn/2019030815160381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTg1MTQy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">然后我们继续输入：<img src="https://img-blog.csdnimg.cn/20190308151624945.png" alt="在这里插入图片描述">继续输入命令：（注意：output1事先一定是不存在的）<br>​    <img src="https://img-blog.csdnimg.cn/20190308151745259.png" alt="在这里插入图片描述">查看计算结果：<br>​    </jar></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop002 hadoop-2.6.0-cdh5.7.0]$ hadoop jar \</span><br><span class="line">./share/hadoop/mapreduce2/hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar \</span><br><span class="line">wordcount /wordcount/input /wordcount/output1</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop002 hadoop-2.6.0-cdh5.7.0]$ hdfs dfs -cat /wordcount/output1/part-r-00000</span><br><span class="line">19/02/16 22:05:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">1       3</span><br><span class="line">3       1</span><br><span class="line">5       1</span><br><span class="line">a       3</span><br><span class="line">adai    1</span><br><span class="line">b       3</span><br><span class="line">c       2</span><br><span class="line">d       1</span><br><span class="line">dashu   1</span><br><span class="line">e       1</span><br><span class="line">f       1</span><br><span class="line">fanren  1</span><br><span class="line">jepon   1</span><br><span class="line">jepson  1</span><br><span class="line">ruoze   3</span><br><span class="line">www.ruozedata.com       1</span><br><span class="line">[hadoop@hadoop002 hadoop-2.6.0-cdh5.7.0]$ hdfs dfs -get /wordcount/output1/part-r-00000 ./</span><br><span class="line">[hadoop@hadoop002 hadoop-2.6.0-cdh5.7.0]$ cat part-r-00000</span><br><span class="line">1       3</span><br><span class="line">3       1</span><br><span class="line">5       1</span><br><span class="line">a       3</span><br><span class="line">adai    1</span><br><span class="line">b       3</span><br><span class="line">c       2</span><br><span class="line">d       1</span><br><span class="line">dashu   1</span><br><span class="line">e       1</span><br><span class="line">f       1</span><br><span class="line">fanren  1</span><br><span class="line">jepon   1</span><br><span class="line">jepson  1</span><br><span class="line">ruoze   3</span><br><span class="line">www.ruozedata.com       1</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/Hadoop参数配置信息/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/Hadoop参数配置信息/" itemprop="url">Hadoop参数配置信息</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T10:30:16+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  29
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<p>前言：</p>
<p>Hadoop三个参数文件，我不是很理解，我网上找了一篇学习下</p>
<p>​       配置hadoop，主要是配置core-site.xml,hdfs-site.xml,mapred-site.xml三个配置文件，默认下来，这些配置文件都是空的，所以很难知道这些配置文件有哪些配置可以生效，上网找的配置可能因为各个hadoop版本不同，导致无法生效。浏览更多的配置，有两个方法:</p>
<p>1.选择相应版本的hadoop,下载解压后，搜索*.xml,找到core-default.xml,hdfs-default.xml,mapred-default.xml,这些就是默认配置,可以参考这些配置的说明和key，配置hadoop集群。</p>
<p>core-site.xml是全局配置,</p>
<p>hdfs-site.xml和mapred-site.xml分别是hdfs和mapred的局部配置。</p>
<p>2       常用的端口配置2.1  HDFS端口</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
<th>默认</th>
<th>配置文件</th>
<th>例子值</th>
</tr>
</thead>
<tbody>
<tr>
<td>fs.default.name namenode</td>
<td>namenode RPC交互端口</td>
<td>8020</td>
<td>core-site.xml</td>
<td>hdfs://master:8020/</td>
</tr>
<tr>
<td>dfs.http.address</td>
<td>NameNode web管理端口</td>
<td>50070</td>
<td>hdfs- site.xml</td>
<td>0.0.0.0:50070</td>
</tr>
<tr>
<td>dfs.datanode.address</td>
<td>datanode　控制端口</td>
<td>50010</td>
<td>hdfs -site.xml</td>
<td>0.0.0.0:50010</td>
</tr>
<tr>
<td>dfs.datanode.ipc.address</td>
<td>datanode的RPC服务器地址和端口</td>
<td>50020</td>
<td>hdfs-site.xml</td>
<td>0.0.0.0:50020</td>
</tr>
<tr>
<td>dfs.datanode.http.address</td>
<td>datanode的HTTP服务器和端口</td>
<td>50075</td>
<td>hdfs-site.xml</td>
<td>0.0.0.0:50075</td>
</tr>
</tbody>
</table>
<p>2.2  MR端口</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
<th>默认</th>
<th>配置文件</th>
<th>例子值</th>
</tr>
</thead>
<tbody>
<tr>
<td>mapred.job.tracker</td>
<td>job-tracker交互端口</td>
<td>8021</td>
<td>mapred-site.xml</td>
<td>hdfs://master:8021/</td>
</tr>
<tr>
<td>job</td>
<td>tracker的web管理端口</td>
<td>50030</td>
<td>mapred-site.xml</td>
<td>0.0.0.0:50030</td>
</tr>
<tr>
<td>mapred.task.tracker.http.address</td>
<td>task-tracker的HTTP端口</td>
<td>50060</td>
<td>mapred-site.xml</td>
<td>0.0.0.0:50060</td>
</tr>
</tbody>
</table>
<p>2.3  其它端口</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
<th>默认</th>
<th>配置文件</th>
<th>例子值</th>
</tr>
</thead>
<tbody>
<tr>
<td>dfs.secondary.http.address</td>
<td>secondary NameNode web管理端口</td>
<td>50090</td>
<td>hdfs-site.xml</td>
<td>0.0.0.0:50090</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>3       三个缺省配置参考文件说明3.1  core-default.html</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>参数名</th>
<th>参数值</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>hadoop.tmp.dir</td>
<td>/tmp/hadoop-${user.name}</td>
<td>临时目录设定</td>
</tr>
<tr>
<td>2</td>
<td>hadoop.native.lib</td>
<td>true</td>
<td>使用本地hadoop库标识。</td>
</tr>
<tr>
<td>3</td>
<td>hadoop.http.filter.initializers</td>
<td></td>
<td>http服务器过滤链设置</td>
</tr>
<tr>
<td>4</td>
<td>hadoop.security.group.mapping</td>
<td>org.apache.hadoop.security.ShellBasedUnixGroupsMapping</td>
<td>组内用户的列表的类设定</td>
</tr>
<tr>
<td>5</td>
<td>hadoop.security.authorization</td>
<td>false</td>
<td>服务端认证开启</td>
</tr>
<tr>
<td>6</td>
<td>hadoop.security.authentication</td>
<td>simple</td>
<td>无认证或认证设置</td>
</tr>
<tr>
<td>7</td>
<td>hadoop.security.token.service.use_ip</td>
<td>true</td>
<td>是否开启使用IP地址作为连接的开关</td>
</tr>
<tr>
<td>8</td>
<td>hadoop.logfile.size</td>
<td>10000000</td>
<td>日志文件最大为10M</td>
</tr>
<tr>
<td>9</td>
<td>hadoop.logfile.count</td>
<td>10</td>
<td>日志文件数量为10个</td>
</tr>
<tr>
<td>10</td>
<td>io.file.buffer.size</td>
<td>4096</td>
<td>流文件的缓冲区为4K</td>
</tr>
<tr>
<td>11</td>
<td>io.bytes.per.checksum</td>
<td>512</td>
<td>校验位数为512字节</td>
</tr>
<tr>
<td>12</td>
<td>io.skip.checksum.errors</td>
<td>false</td>
<td>校验出错后是抛出异常还是略过标识。True则略过。</td>
</tr>
<tr>
<td>13</td>
<td>io.compression.codecs</td>
<td>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec</td>
<td>压缩和解压的方式设置</td>
</tr>
<tr>
<td>14</td>
<td>io.serializations</td>
<td>org.apache.hadoop.io.serializer.WritableSerialization</td>
<td>序例化和反序列化的类设定</td>
</tr>
<tr>
<td>15</td>
<td>fs.default.name</td>
<td>file:///</td>
<td>缺省的文件URI标识设定。</td>
</tr>
<tr>
<td>16</td>
<td>fs.trash.interval</td>
<td>0</td>
<td>文件废弃标识设定，0为禁止此功能</td>
</tr>
<tr>
<td>17</td>
<td>fs.file.impl</td>
<td>org.apache.hadoop.fs.LocalFileSystem</td>
<td>本地文件操作类设置</td>
</tr>
<tr>
<td>18</td>
<td>fs.hdfs.impl</td>
<td>org.apache.hadoop.hdfs.DistributedFileSystem</td>
<td>HDFS文件操作类设置</td>
</tr>
<tr>
<td>19</td>
<td>fs.s3.impl</td>
<td>org.apache.hadoop.fs.s3.S3FileSystem</td>
<td>S3文件操作类设置</td>
</tr>
<tr>
<td>20</td>
<td>fs.s3n.impl</td>
<td>org.apache.hadoop.fs.s3native.NativeS3FileSystem</td>
<td>S3文件本地操作类设置</td>
</tr>
<tr>
<td>21</td>
<td>fs.kfs.impl</td>
<td>org.apache.hadoop.fs.kfs.KosmosFileSystem</td>
<td>KFS文件操作类设置.</td>
</tr>
<tr>
<td>22</td>
<td>fs.hftp.impl</td>
<td>org.apache.hadoop.hdfs.HftpFileSystem</td>
<td>HTTP方式操作文件设置</td>
</tr>
<tr>
<td>23</td>
<td>fs.hsftp.impl</td>
<td>org.apache.hadoop.hdfs.HsftpFileSystem</td>
<td>HTTPS方式操作文件设置</td>
</tr>
<tr>
<td>24</td>
<td>fs.webhdfs.impl</td>
<td>org.apache.hadoop.hdfs.web.WebHdfsFileSystem</td>
<td>WEB方式操作文件类设置</td>
</tr>
<tr>
<td>25</td>
<td>fs.ftp.impl</td>
<td>org.apache.hadoop.fs.ftp.FTPFileSystem</td>
<td>FTP文件操作类设置</td>
</tr>
<tr>
<td>26</td>
<td>fs.ramfs.impl</td>
<td>org.apache.hadoop.fs.InMemoryFileSystem</td>
<td>内存文件操作类设置</td>
</tr>
<tr>
<td>27</td>
<td>fs.har.impl</td>
<td>org.apache.hadoop.fs.HarFileSystem</td>
<td>压缩文件操作类设置.</td>
</tr>
<tr>
<td>28</td>
<td>fs.har.impl.disable.cache</td>
<td>true</td>
<td>是否缓存har文件的标识设定</td>
</tr>
<tr>
<td>29</td>
<td>fs.checkpoint.dir</td>
<td>${hadoop.tmp.dir}/dfs/namesecondary</td>
<td>备份名称节点的存放目前录设置</td>
</tr>
<tr>
<td>30</td>
<td>fs.checkpoint.edits.dir</td>
<td>${fs.checkpoint.dir}</td>
<td>备份名称节点日志文件的存放目前录设置</td>
</tr>
<tr>
<td>31</td>
<td>fs.checkpoint.period</td>
<td>3600</td>
<td>动态检查的间隔时间设置</td>
</tr>
<tr>
<td>32</td>
<td>fs.checkpoint.size</td>
<td>67108864</td>
<td>日志文件大小为64M</td>
</tr>
<tr>
<td>33</td>
<td>fs.s3.block.size</td>
<td>67108864</td>
<td>写S3文件系统的块的大小为64M</td>
</tr>
<tr>
<td>34</td>
<td>fs.s3.buffer.dir</td>
<td>${hadoop.tmp.dir}/s3</td>
<td>S3文件数据的本地存放目录</td>
</tr>
<tr>
<td>35</td>
<td>fs.s3.maxRetries</td>
<td>4</td>
<td>S3文件数据的偿试读写次数</td>
</tr>
<tr>
<td>36</td>
<td>fs.s3.sleepTimeSeconds</td>
<td>10</td>
<td>S3文件偿试的间隔</td>
</tr>
<tr>
<td>37</td>
<td>local.cache.size</td>
<td>10737418240</td>
<td>缓存大小设置为10GB</td>
</tr>
<tr>
<td>38</td>
<td>io.seqfile.compress.blocksize</td>
<td>1000000</td>
<td>压缩流式文件中的最小块数为100万</td>
</tr>
<tr>
<td>39</td>
<td>io.seqfile.lazydecompress</td>
<td>true</td>
<td>块是否需要压缩标识设定</td>
</tr>
<tr>
<td>40</td>
<td>io.seqfile.sorter.recordlimit</td>
<td>1000000</td>
<td>内存中排序记录块类最小为100万</td>
</tr>
<tr>
<td>41</td>
<td>io.mapfile.bloom.size</td>
<td>1048576</td>
<td>BloomMapFiler过滤量为1M</td>
</tr>
<tr>
<td>42</td>
<td>io.mapfile.bloom.error.rate</td>
<td>0.005</td>
<td></td>
</tr>
<tr>
<td>43</td>
<td>hadoop.util.hash.type</td>
<td>murmur</td>
<td>缺少hash方法为murmur</td>
</tr>
<tr>
<td>44</td>
<td>ipc.client.idlethreshold</td>
<td>4000</td>
<td>连接数据最小阀值为4000</td>
</tr>
<tr>
<td>45</td>
<td>ipc.client.kill.max</td>
<td>10</td>
<td>一个客户端连接数最大值为10</td>
</tr>
<tr>
<td>46</td>
<td>ipc.client.connection.maxidletime</td>
<td>10000</td>
<td>断开与服务器连接的时间最大为10秒</td>
</tr>
<tr>
<td>47</td>
<td>ipc.client.connect.max.retries</td>
<td>10</td>
<td>建立与服务器连接的重试次数为10次</td>
</tr>
<tr>
<td>48</td>
<td>ipc.server.listen.queue.size</td>
<td>128</td>
<td>接收客户连接的监听队例的长度为128</td>
</tr>
<tr>
<td>49</td>
<td>ipc.server.tcpnodelay</td>
<td>false</td>
<td>开启或关闭服务器端TCP连接算法</td>
</tr>
<tr>
<td>50</td>
<td>ipc.client.tcpnodelay</td>
<td>false</td>
<td>开启或关闭客户端TCP连接算法</td>
</tr>
<tr>
<td>51</td>
<td>webinterface.private.actions</td>
<td>false</td>
<td>Web交互的行为设定</td>
</tr>
<tr>
<td>52</td>
<td>hadoop.rpc.socket.factory.class.default</td>
<td>org.apache.hadoop.net.StandardSocketFactory</td>
<td>缺省的socket工厂类设置</td>
</tr>
<tr>
<td>53</td>
<td>hadoop.rpc.socket.factory.class.ClientProtocol</td>
<td></td>
<td>与dfs连接时的缺省socket工厂类</td>
</tr>
<tr>
<td>54</td>
<td>hadoop.socks.server</td>
<td></td>
<td>服务端的工厂类缺省设置为SocksSocketFactory.</td>
</tr>
<tr>
<td>55</td>
<td>topology.node.switch.mapping.impl</td>
<td>org.apache.hadoop.net.ScriptBasedMapping</td>
<td></td>
</tr>
<tr>
<td>56</td>
<td>topology.script.file.name</td>
<td></td>
<td></td>
</tr>
<tr>
<td>57</td>
<td>topology.script.number.args</td>
<td>100</td>
<td>参数数量最多为100</td>
</tr>
<tr>
<td>58</td>
<td>hadoop.security.uid.cache.secs</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>3.2  hdfs-default.html</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>参数名</th>
<th>参数值</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>dfs.namenode.logging.level</td>
<td>info</td>
<td>输出日志类型</td>
</tr>
<tr>
<td>2</td>
<td>dfs.secondary.http.address</td>
<td>0.0.0.0:50090</td>
<td>备份名称节点的http协议访问地址与端口</td>
</tr>
<tr>
<td>3</td>
<td>dfs.datanode.address</td>
<td>0.0.0.0:50010</td>
<td>数据节点的TCP管理服务地址和端口</td>
</tr>
<tr>
<td>4</td>
<td>dfs.datanode.http.address</td>
<td>0.0.0.0:50075</td>
<td>数据节点的HTTP协议访问地址和端口</td>
</tr>
<tr>
<td>5</td>
<td>dfs.datanode.ipc.address</td>
<td>0.0.0.0:50020</td>
<td>数据节点的IPC服务访问地址和端口</td>
</tr>
<tr>
<td>6</td>
<td>dfs.datanode.handler.count</td>
<td>3</td>
<td>数据节点的服务连接处理线程数</td>
</tr>
<tr>
<td>7</td>
<td>dfs.http.address</td>
<td>0.0.0.0:50070</td>
<td>名称节点的http协议访问地址与端口</td>
</tr>
<tr>
<td>8</td>
<td>dfs.https.enable</td>
<td>false</td>
<td>支持https访问方式标识</td>
</tr>
<tr>
<td>9</td>
<td>dfs.https.need.client.auth</td>
<td>false</td>
<td>客户端指定https访问标识</td>
</tr>
<tr>
<td>10</td>
<td>dfs.https.server.keystore.resource</td>
<td>ssl-server.xml</td>
<td>Ssl密钥服务端的配置文件</td>
</tr>
<tr>
<td>11</td>
<td>dfs.https.client.keystore.resource</td>
<td>ssl-client.xml</td>
<td>Ssl密钥客户端的配置文件</td>
</tr>
<tr>
<td>12</td>
<td>dfs.datanode.https.address</td>
<td>0.0.0.0:50475</td>
<td>数据节点的HTTPS协议访问地址和端口</td>
</tr>
<tr>
<td>13</td>
<td>dfs.https.address</td>
<td>0.0.0.0:50470</td>
<td>名称节点的HTTPS协议访问地址和端口</td>
</tr>
<tr>
<td>14</td>
<td>dfs.datanode.dns.interface</td>
<td>default</td>
<td>数据节点采用IP地址标识</td>
</tr>
<tr>
<td>15</td>
<td>dfs.datanode.dns.nameserver</td>
<td>default</td>
<td>指定DNS的IP地址</td>
</tr>
<tr>
<td>16</td>
<td>dfs.replication.considerLoad</td>
<td>true</td>
<td>加载目标或不加载的标识</td>
</tr>
<tr>
<td>17</td>
<td>dfs.default.chunk.view.size</td>
<td>32768</td>
<td>浏览时的文件块大小设置为32K</td>
</tr>
<tr>
<td>18</td>
<td>dfs.datanode.du.reserved</td>
<td>0</td>
<td>每个卷预留的空闲空间数量</td>
</tr>
<tr>
<td>19</td>
<td>dfs.name.dir</td>
<td>${hadoop.tmp.dir}/dfs/name</td>
<td>存贮在本地的名字节点数据镜象的目录,作为名字节点的冗余备份</td>
</tr>
<tr>
<td>20</td>
<td>dfs.name.edits.dir</td>
<td>${dfs.name.dir}</td>
<td>存贮文件操作过程信息的存贮目录</td>
</tr>
<tr>
<td>21</td>
<td>dfs.web.ugi</td>
<td>webuser,webgroup</td>
<td>Web接口访问的用户名和组的帐户设定</td>
</tr>
<tr>
<td>22</td>
<td>dfs.permissions</td>
<td>true</td>
<td>文件操作时的权限检查标识。</td>
</tr>
<tr>
<td>23</td>
<td>dfs.permissions.supergroup</td>
<td>supergroup</td>
<td>超级用户的组名定义</td>
</tr>
<tr>
<td>24</td>
<td>dfs.block.access.token.enable</td>
<td>false</td>
<td>数据节点访问令牌标识</td>
</tr>
<tr>
<td>25</td>
<td>dfs.block.access.key.update.interval</td>
<td>600</td>
<td>升级访问钥时的间隔时间</td>
</tr>
<tr>
<td>26</td>
<td>dfs.block.access.token.lifetime</td>
<td>600</td>
<td>访问令牌的有效时间</td>
</tr>
<tr>
<td>27</td>
<td>dfs.data.dir</td>
<td>${hadoop.tmp.dir}/dfs/data</td>
<td>数据节点的块本地存放目录</td>
</tr>
<tr>
<td>28</td>
<td>dfs.datanode.data.dir.perm</td>
<td>755</td>
<td>数据节点的存贮块的目录访问权限设置</td>
</tr>
<tr>
<td>29</td>
<td>dfs.replication</td>
<td>3</td>
<td>缺省的块复制数量</td>
</tr>
<tr>
<td>30</td>
<td>dfs.replication.max</td>
<td>512</td>
<td>块复制的最大数量</td>
</tr>
<tr>
<td>31</td>
<td>dfs.replication.min</td>
<td>1</td>
<td>块复制的最小数量</td>
</tr>
<tr>
<td>32</td>
<td>dfs.block.size</td>
<td>67108864</td>
<td>缺省的文件块大小为64M</td>
</tr>
<tr>
<td>33</td>
<td>dfs.df.interval</td>
<td>60000</td>
<td>磁盘空间统计间隔为6秒</td>
</tr>
<tr>
<td>34</td>
<td>dfs.client.block.write.retries</td>
<td>3</td>
<td>块写入出错时的重试次数</td>
</tr>
<tr>
<td>35</td>
<td>dfs.blockreport.intervalMsec</td>
<td>3600000</td>
<td>块的报告间隔时为1小时</td>
</tr>
<tr>
<td>36</td>
<td>dfs.blockreport.initialDelay</td>
<td>0</td>
<td>块顺序报告的间隔时间</td>
</tr>
<tr>
<td>37</td>
<td>dfs.heartbeat.interval</td>
<td>3</td>
<td>数据节点的心跳检测间隔时间</td>
</tr>
<tr>
<td>38</td>
<td>dfs.namenode.handler.count</td>
<td>10</td>
<td>名称节点的连接处理的线程数量</td>
</tr>
<tr>
<td>39</td>
<td>dfs.safemode.threshold.pct</td>
<td>0.999f</td>
<td>启动安全模式的阀值设定</td>
</tr>
<tr>
<td>40</td>
<td>dfs.safemode.extension</td>
<td>30000</td>
<td>当阀值达到量值后扩展的时限</td>
</tr>
<tr>
<td>41</td>
<td>dfs.balance.bandwidthPerSec</td>
<td>1048576</td>
<td>启动负载均衡的数据节点可利用带宽最大值为1M</td>
</tr>
<tr>
<td>42</td>
<td>dfs.hosts</td>
<td></td>
<td>可与名称节点连接的主机地址文件指定。</td>
</tr>
<tr>
<td>43</td>
<td>dfs.hosts.exclude</td>
<td></td>
<td>不充计与名称节点连接的主机地址文件设定</td>
</tr>
<tr>
<td>44</td>
<td>dfs.max.objects</td>
<td>0</td>
<td>文件数、目录数、块数的最大数量</td>
</tr>
<tr>
<td>45</td>
<td>dfs.namenode.decommission.interval</td>
<td>30</td>
<td>名称节点解除命令执行时的监测时间周期</td>
</tr>
<tr>
<td>46</td>
<td>dfs.namenode.decommission.nodes.per.interval</td>
<td>5</td>
<td>名称节点解除命令执行是否完检测次数</td>
</tr>
<tr>
<td>47</td>
<td>dfs.replication.interval</td>
<td>3</td>
<td>名称节点计算数据节点的复制工作的周期数.</td>
</tr>
<tr>
<td>48</td>
<td>dfs.access.time.precision</td>
<td>3600000</td>
<td>充许访问文件的时间精确到1小时</td>
</tr>
<tr>
<td>49</td>
<td>dfs.support.append</td>
<td>false</td>
<td>是否充许链接文件指定</td>
</tr>
<tr>
<td>50</td>
<td>dfs.namenode.delegation.key.update-interval</td>
<td>86400000</td>
<td>名称节点上的代理令牌的主key的更新间隔时间为24小时</td>
</tr>
<tr>
<td>51</td>
<td>dfs.namenode.delegation.token.max-lifetime</td>
<td>604800000</td>
<td>代理令牌的有效时间最大值为7天</td>
</tr>
<tr>
<td>52</td>
<td>dfs.namenode.delegation.token.renew-interval</td>
<td>86400000</td>
<td>代理令牌的更新时间为24小时</td>
</tr>
<tr>
<td>53</td>
<td>dfs.datanode.failed.volumes.tolerated</td>
<td>0</td>
<td>决定停止数据节点提供服务充许卷的出错次数。0次则任何卷出错都要停止数据节点</td>
</tr>
</tbody>
</table>
<p>3.3  mapred-default.html</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>参数名</th>
<th>参数值</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>hadoop.job.history.location</td>
<td></td>
<td>作业跟踪管理器的静态历史文件的存放目录。</td>
</tr>
<tr>
<td>2</td>
<td>hadoop.job.history.user.location</td>
<td></td>
<td>可以指定具体某个作业的跟踪管理器的历史文件存放目录</td>
</tr>
<tr>
<td>3</td>
<td>mapred.job.tracker.history.completed.location</td>
<td></td>
<td>已完成作业的历史文件的存放目录</td>
</tr>
<tr>
<td>4</td>
<td>io.sort.factor</td>
<td>10</td>
<td>排完序的文件的合并时的打开文件句柄数</td>
</tr>
<tr>
<td>5</td>
<td>io.sort.mb</td>
<td>100</td>
<td>排序文件的内存缓存大小为100M</td>
</tr>
<tr>
<td>6</td>
<td>io.sort.record.percent</td>
<td>0.05</td>
<td>排序线程阻塞的内存缓存剩余比率</td>
</tr>
<tr>
<td>7</td>
<td>io.sort.spill.percent</td>
<td>0.80</td>
<td>当缓冲占用量为该值时，线程需要将内容先备份到磁盘中。</td>
</tr>
<tr>
<td>8</td>
<td>io.map.index.skip</td>
<td>0</td>
<td>索引条目的间隔设定</td>
</tr>
<tr>
<td>9</td>
<td>mapred.job.tracker</td>
<td>local</td>
<td>作业跟踪管理器是否和MR任务在一个进程中</td>
</tr>
<tr>
<td>10</td>
<td>mapred.job.tracker.http.address</td>
<td>0.0.0.0:50030</td>
<td>作业跟踪管理器的HTTP服务器访问端口和地址</td>
</tr>
<tr>
<td>11</td>
<td>mapred.job.tracker.handler.count</td>
<td>10</td>
<td>作业跟踪管理器的管理线程数,线程数比例是任务管理跟踪器数量的0.04</td>
</tr>
<tr>
<td>12</td>
<td>mapred.task.tracker.report.address</td>
<td>127.0.0.1:0</td>
<td>任务管理跟踪器的主机地址和端口地址</td>
</tr>
<tr>
<td>13</td>
<td>mapred.local.dir</td>
<td>${hadoop.tmp.dir}/mapred/local</td>
<td>MR的中介数据文件存放目录</td>
</tr>
<tr>
<td>14</td>
<td>mapred.system.dir</td>
<td>${hadoop.tmp.dir}/mapred/system</td>
<td>MR的控制文件存放目录</td>
</tr>
<tr>
<td>15</td>
<td>mapreduce.jobtracker.staging.root.dir</td>
<td>${hadoop.tmp.dir}/mapred/staging</td>
<td>每个正在运行作业文件的存放区</td>
</tr>
<tr>
<td>16</td>
<td>mapred.temp.dir</td>
<td>${hadoop.tmp.dir}/mapred/temp</td>
<td>MR临时共享文件存放区</td>
</tr>
<tr>
<td>17</td>
<td>mapred.local.dir.minspacestart</td>
<td>0</td>
<td>MR本地中介文件删除时，不充许有任务执行的数量值。</td>
</tr>
<tr>
<td>18</td>
<td>mapred.local.dir.minspacekill</td>
<td>0</td>
<td>MR本地中介文件删除时，除非所有任务都已完成的数量值。</td>
</tr>
<tr>
<td>19</td>
<td>mapred.tasktracker.expiry.interval</td>
<td>600000</td>
<td>任务管理跟踪器不发送心跳的累计时间间隔超过600秒，则任务管理跟踪器失效</td>
</tr>
<tr>
<td>20</td>
<td>mapred.tasktracker.resourcecalculatorplugin</td>
<td></td>
<td>指定的一个用户访问资源信息的类实例</td>
</tr>
<tr>
<td>21</td>
<td>mapred.tasktracker.taskmemorymanager.monitoring-interval</td>
<td>5000</td>
<td>监控任务管理跟踪器任务内存使用率的时间间隔</td>
</tr>
<tr>
<td>22</td>
<td>mapred.tasktracker.tasks.sleeptime-before-sigkill</td>
<td>5000</td>
<td>发出进程终止后，间隔5秒后发出进程消亡信号</td>
</tr>
<tr>
<td>23</td>
<td>mapred.map.tasks</td>
<td>2</td>
<td>每个作业缺省的map任务数为2</td>
</tr>
<tr>
<td>24</td>
<td>mapred.reduce.tasks</td>
<td>1</td>
<td>每个作业缺省的reduce任务数为1</td>
</tr>
<tr>
<td>25</td>
<td>mapreduce.tasktracker.outofband.heartbeat</td>
<td>false</td>
<td>让在任务结束后发出一个额外的心跳信号</td>
</tr>
<tr>
<td>26</td>
<td>mapreduce.tasktracker.outofband.heartbeat.damper</td>
<td>1000000</td>
<td>当额外心跳信号发出量太多时，则适当阻止</td>
</tr>
<tr>
<td>27</td>
<td>mapred.jobtracker.restart.recover</td>
<td>false</td>
<td>充许任务管理器恢复时采用的方式</td>
</tr>
<tr>
<td>28</td>
<td>mapred.jobtracker.job.history.block.size</td>
<td>3145728</td>
<td>作业历史文件块的大小为3M</td>
</tr>
<tr>
<td>29</td>
<td>mapreduce.job.split.metainfo.maxsize</td>
<td>10000000</td>
<td>分隔元信息文件的最大值是10M以下</td>
</tr>
<tr>
<td>30</td>
<td>mapred.jobtracker.taskScheduler</td>
<td>org.apache.hadoop.mapred.JobQueueTaskScheduler</td>
<td>设定任务的执行计划实现类</td>
</tr>
<tr>
<td>31</td>
<td>mapred.jobtracker.taskScheduler.maxRunningTasksPerJob</td>
<td></td>
<td>作业同时运行的任务数的最大值</td>
</tr>
<tr>
<td>32</td>
<td>mapred.map.max.attempts</td>
<td>4</td>
<td>Map任务的重试次数</td>
</tr>
<tr>
<td>33</td>
<td>mapred.reduce.max.attempts</td>
<td>4</td>
<td>Reduce任务的重试次数</td>
</tr>
<tr>
<td>34</td>
<td>mapred.reduce.parallel.copies</td>
<td>5</td>
<td>在复制阶段时reduce并行传送的值。</td>
</tr>
<tr>
<td>35</td>
<td>mapreduce.reduce.shuffle.maxfetchfailures</td>
<td>10</td>
<td>取map输出的最大重试次数</td>
</tr>
<tr>
<td>36</td>
<td>mapreduce.reduce.shuffle.connect.timeout</td>
<td>180000</td>
<td>REDUCE任务连接任务管理器获得map输出时的总耗时是3分钟</td>
</tr>
<tr>
<td>37</td>
<td>mapreduce.reduce.shuffle.read.timeout</td>
<td>180000</td>
<td>REDUCE任务等待map输出数据的总耗时是3分钟</td>
</tr>
<tr>
<td>38</td>
<td>mapred.task.timeout</td>
<td>600000</td>
<td>如果任务无读无写时的时间耗时为10分钟，将被终止</td>
</tr>
<tr>
<td>39</td>
<td>mapred.tasktracker.map.tasks.maximum</td>
<td>2</td>
<td>任管管理器可同时运行map任务数为2</td>
</tr>
<tr>
<td>40</td>
<td>mapred.tasktracker.reduce.tasks.maximum</td>
<td>2</td>
<td>任管管理器可同时运行reduce任务数为2</td>
</tr>
<tr>
<td>41</td>
<td>mapred.jobtracker.completeuserjobs.maximum</td>
<td>100</td>
<td>当用户的完成作业数达100个后，将其放入作业历史文件中</td>
</tr>
<tr>
<td>42</td>
<td>mapreduce.reduce.input.limit</td>
<td>-1</td>
<td>Reduce输入量的限制。</td>
</tr>
<tr>
<td>43</td>
<td>mapred.job.tracker.retiredjobs.cache.size</td>
<td>1000</td>
<td>作业状态为已不在执行的保留在内存中的量为1000</td>
</tr>
<tr>
<td>44</td>
<td>mapred.job.tracker.jobhistory.lru.cache.size</td>
<td>5</td>
<td>作业历史文件装载到内存的数量</td>
</tr>
<tr>
<td>45</td>
<td>mapred.child.java.opts</td>
<td>-Xmx200m</td>
<td>启动task管理的子进程时的内存设置</td>
</tr>
<tr>
<td>46</td>
<td>mapred.child.env</td>
<td></td>
<td>子进程的参数设置</td>
</tr>
<tr>
<td>47</td>
<td>mapred.child.ulimit</td>
<td></td>
<td>虚拟机所需内存的设定。</td>
</tr>
<tr>
<td>48</td>
<td>mapred.cluster.map.memory.mb</td>
<td>-1</td>
<td></td>
</tr>
<tr>
<td>49</td>
<td>mapred.cluster.reduce.memory.mb</td>
<td>-1</td>
<td></td>
</tr>
<tr>
<td>50</td>
<td>mapred.cluster.max.map.memory.mb</td>
<td>-1</td>
<td></td>
</tr>
<tr>
<td>51</td>
<td>mapred.cluster.max.reduce.memory.mb</td>
<td>-1</td>
<td></td>
</tr>
<tr>
<td>52</td>
<td>mapred.job.map.memory.mb</td>
<td>-1</td>
<td></td>
</tr>
<tr>
<td>53</td>
<td>mapred.job.reduce.memory.mb</td>
<td>-1</td>
<td></td>
</tr>
<tr>
<td>54</td>
<td>mapred.child.tmp</td>
<td>/tmp</td>
<td>Mr任务信息的存放目录</td>
</tr>
<tr>
<td>55</td>
<td>mapred.inmem.merge.threshold</td>
<td>1000</td>
<td>内存中的合并文件数设置</td>
</tr>
<tr>
<td>56</td>
<td>mapred.job.shuffle.merge.percent</td>
<td>0.66</td>
<td></td>
</tr>
<tr>
<td>57</td>
<td>mapred.job.shuffle.input.buffer.percent</td>
<td>0.70</td>
<td></td>
</tr>
<tr>
<td>58</td>
<td>mapred.job.reduce.input.buffer.percent</td>
<td>0.0</td>
<td></td>
</tr>
<tr>
<td>59</td>
<td>mapred.map.tasks.speculative.execution</td>
<td>true</td>
<td>Map任务的多实例并行运行标识</td>
</tr>
<tr>
<td>60</td>
<td>mapred.reduce.tasks.speculative.execution</td>
<td>true</td>
<td>Reduce任务的多实例并行运行标识</td>
</tr>
<tr>
<td>61</td>
<td>mapred.job.reuse.jvm.num.tasks</td>
<td>1</td>
<td>每虚拟机运行的任务数</td>
</tr>
<tr>
<td>62</td>
<td>mapred.min.split.size</td>
<td>0</td>
<td>Map的输入数据被分解的块数设置</td>
</tr>
<tr>
<td>63</td>
<td>mapred.jobtracker.maxtasks.per.job</td>
<td>-1</td>
<td>一个单独作业的任务数设置</td>
</tr>
<tr>
<td>64</td>
<td>mapred.submit.replication</td>
<td>10</td>
<td>提交作业文件的复制级别</td>
</tr>
<tr>
<td>65</td>
<td>mapred.tasktracker.dns.interface</td>
<td>default</td>
<td>任务管理跟踪器是否报告IP地址名的开关</td>
</tr>
<tr>
<td>66</td>
<td>mapred.tasktracker.dns.nameserver</td>
<td>default</td>
<td>作业和任务管理跟踪器之间通讯方式采用的DNS服务的主机名或IP地址</td>
</tr>
<tr>
<td>67</td>
<td>tasktracker.http.threads</td>
<td>40</td>
<td>http服务器的工作线程数量</td>
</tr>
<tr>
<td>68</td>
<td>mapred.task.tracker.http.address</td>
<td>0.0.0.0:50060</td>
<td>任务管理跟踪器的http服务器的地址和端口</td>
</tr>
<tr>
<td>69</td>
<td>keep.failed.task.files</td>
<td>false</td>
<td>失败任务是否保存到文件中</td>
</tr>
<tr>
<td>70</td>
<td>mapred.output.compress</td>
<td>false</td>
<td>作业的输出是否压缩</td>
</tr>
<tr>
<td>71</td>
<td>mapred.output.compression.type</td>
<td>RECORD</td>
<td>作业输出采用NONE, RECORD or BLOCK三种方式中一种压缩的写入到流式文件</td>
</tr>
<tr>
<td>72</td>
<td>mapred.output.compression.codec</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
<td>压缩类的设置</td>
</tr>
<tr>
<td>73</td>
<td>mapred.compress.map.output</td>
<td>false</td>
<td>Map的输出是否压缩</td>
</tr>
<tr>
<td>74</td>
<td>mapred.map.output.compression.codec</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
<td>Map的输出压缩的实现类指定</td>
</tr>
<tr>
<td>75</td>
<td>map.sort.class</td>
<td>org.apache.hadoop.util.QuickSort</td>
<td>排序键的排序类指定</td>
</tr>
<tr>
<td>76</td>
<td>mapred.userlog.limit.kb</td>
<td>0</td>
<td>每个任务的用户日志文件大小</td>
</tr>
<tr>
<td>77</td>
<td>mapred.userlog.retain.hours</td>
<td>24</td>
<td>作业完成后的用户日志留存时间为24小时</td>
</tr>
<tr>
<td>78</td>
<td>mapred.user.jobconf.limit</td>
<td>5242880</td>
<td>Jobconf的大小为5M</td>
</tr>
<tr>
<td>79</td>
<td>mapred.hosts</td>
<td></td>
<td>可与作业管理跟踪器连接的主机名</td>
</tr>
<tr>
<td>80</td>
<td>mapred.hosts.exclude</td>
<td></td>
<td>不可与作业管理跟踪器连接的主机名</td>
</tr>
<tr>
<td>81</td>
<td>mapred.heartbeats.in.second</td>
<td>100</td>
<td>作业管理跟踪器的每秒中到达的心跳数量为100</td>
</tr>
<tr>
<td>82</td>
<td>mapred.max.tracker.blacklists</td>
<td>4</td>
<td>任务管理跟踪器的黑名单列表的数量</td>
</tr>
<tr>
<td>83</td>
<td>mapred.jobtracker.blacklist.fault-timeout-window</td>
<td>180</td>
<td>任务管理跟踪器超时180分钟则訪任务将被重启</td>
</tr>
<tr>
<td>84</td>
<td>mapred.jobtracker.blacklist.fault-bucket-width</td>
<td>15</td>
<td></td>
</tr>
<tr>
<td>85</td>
<td>mapred.max.tracker.failures</td>
<td>4</td>
<td>任务管理跟踪器的失败任务数设定</td>
</tr>
<tr>
<td>86</td>
<td>jobclient.output.filter</td>
<td>FAILED</td>
<td>控制任务的用户日志输出到作业端时的过滤方式</td>
</tr>
<tr>
<td>87</td>
<td>mapred.job.tracker.persist.jobstatus.active</td>
<td>false</td>
<td>是否持久化作业管理跟踪器的信息</td>
</tr>
<tr>
<td>88</td>
<td>mapred.job.tracker.persist.jobstatus.hours</td>
<td>0</td>
<td>持久化作业管理跟踪器的信息的保存时间</td>
</tr>
<tr>
<td>89</td>
<td>mapred.job.tracker.persist.jobstatus.dir</td>
<td>/jobtracker/jobsInfo</td>
<td>作业管理跟踪器的信息存放目录</td>
</tr>
<tr>
<td>90</td>
<td>mapreduce.job.complete.cancel.delegation.tokens</td>
<td>true</td>
<td>恢复时是否变更领牌</td>
</tr>
<tr>
<td>91</td>
<td>mapred.task.profile</td>
<td>false</td>
<td>任务分析信息是否建设标志</td>
</tr>
<tr>
<td>92</td>
<td>mapred.task.profile.maps</td>
<td>0-2</td>
<td>设置map任务的分析范围</td>
</tr>
<tr>
<td>93</td>
<td>mapred.task.profile.reduces</td>
<td>0-2</td>
<td>设置reduce任务的分析范围</td>
</tr>
<tr>
<td>94</td>
<td>mapred.line.input.format.linespermap</td>
<td>1</td>
<td>每次切分的行数设置</td>
</tr>
<tr>
<td>95</td>
<td>mapred.skip.attempts.to.start.skipping</td>
<td>2</td>
<td>在跳转模式未被设定的情况下任务的重试次数</td>
</tr>
<tr>
<td>96</td>
<td>mapred.skip.map.auto.incr.proc.count</td>
<td>true</td>
<td>MapRunner在调用map功能后的增量处理方式设置</td>
</tr>
<tr>
<td>97</td>
<td>mapred.skip.reduce.auto.incr.proc.count</td>
<td>true</td>
<td>在调用reduce功能后的增量处理方式设置</td>
</tr>
<tr>
<td>98</td>
<td>mapred.skip.out.dir</td>
<td></td>
<td>跳过记录的输出目录</td>
</tr>
<tr>
<td>99</td>
<td>mapred.skip.map.max.skip.records</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>100</td>
<td>mapred.skip.reduce.max.skip.groups</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>101</td>
<td>job.end.retry.attempts</td>
<td>0</td>
<td>Hadoop偿试连接通知器的次数</td>
</tr>
<tr>
<td>102</td>
<td>job.end.retry.interval</td>
<td>30000</td>
<td>通知偿试回应的间隔操作为30秒</td>
</tr>
<tr>
<td>103</td>
<td>hadoop.rpc.socket.factory.class.JobSubmissionProtocol</td>
<td></td>
<td>指定与作业跟踪管理器的通讯方式，缺省是采用rpc方式</td>
</tr>
<tr>
<td>104</td>
<td>mapred.task.cache.levels</td>
<td>2</td>
<td>任务缓存级别设置</td>
</tr>
<tr>
<td>105</td>
<td>mapred.queue.names</td>
<td>default</td>
<td>分隔作业队例的分隔符设定</td>
</tr>
<tr>
<td>106</td>
<td>mapred.acls.enabled</td>
<td>false</td>
<td>指定ACL访问控制列表</td>
</tr>
<tr>
<td>107</td>
<td>mapred.queue.default.state</td>
<td>RUNNING</td>
<td>定义队列的状态</td>
</tr>
<tr>
<td>108</td>
<td>mapred.job.queue.name</td>
<td>default</td>
<td>已提交作业的队列设定</td>
</tr>
<tr>
<td>109</td>
<td>mapreduce.job.acl-modify-job</td>
<td></td>
<td>指定可修改作业的ACL列表</td>
</tr>
<tr>
<td>110</td>
<td>mapreduce.job.acl-view-job</td>
<td></td>
<td>指定可浏临作业的ACL列表</td>
</tr>
<tr>
<td>111</td>
<td>mapred.tasktracker.indexcache.mb</td>
<td>10</td>
<td>任务管理跟踪器的索引内存的最大容器</td>
</tr>
<tr>
<td>112</td>
<td>mapred.combine.recordsBeforeProgress</td>
<td>10000</td>
<td>在聚合处理时的记录块数</td>
</tr>
<tr>
<td>113</td>
<td>mapred.merge.recordsBeforeProgress</td>
<td>10000</td>
<td>在汇总处理时的记录块数</td>
</tr>
<tr>
<td>114</td>
<td>mapred.reduce.slowstart.completed.maps</td>
<td>0.05</td>
<td></td>
</tr>
<tr>
<td>115</td>
<td>mapred.task.tracker.task-controller</td>
<td>org.apache.hadoop.mapred.DefaultTaskController</td>
<td>任务管理器的设定</td>
</tr>
<tr>
<td>116</td>
<td>mapreduce.tasktracker.group</td>
<td></td>
<td>任务管理器的组成员设定</td>
</tr>
<tr>
<td>117</td>
<td>mapred.healthChecker.script.path</td>
<td></td>
<td>脚本的绝对路径指定，这些脚本是心跳服务的</td>
</tr>
<tr>
<td>118</td>
<td>mapred.healthChecker.interval</td>
<td>60000</td>
<td>节点心跳信息的间隔</td>
</tr>
<tr>
<td>119</td>
<td>mapred.healthChecker.script.timeout</td>
<td>600000</td>
<td></td>
</tr>
<tr>
<td>120</td>
<td>mapred.healthChecker.script.args</td>
<td></td>
<td>参数列表</td>
</tr>
<tr>
<td>121</td>
<td>mapreduce.job.counters.limit</td>
<td>120</td>
<td>作业计数器的最小值</td>
</tr>
</tbody>
</table>
<p>配置hadoop，主要是配置core-site.xml,hdfs-site.xml,mapred-site.xml三个配置文件，默认下来，这些配置文件都是空的，所以很难知道这些配置文件有哪些配置可以生效，上网找的配置可能因为各个hadoop版本不同，导致无法生效。浏览更多的配置，有两个方法:</p>
<p>1.选择相应版本的hadoop,下载解压后，搜索*.xml,找到core-default.xml,hdfs-default.xml,mapred-default.xml,这些就是默认配置,可以参考这些配置的说明和key，配置hadoop集群。</p>
<p>2.浏览apache官网,三个配置文件链接如下:</p>
<p>   <a href="http://hadoop.apache.org/common/docs/current/core-default.html" target="_blank" rel="noopener">http://hadoop.apache.org/common/docs/current/core-default.html</a></p>
<p>   <a href="http://hadoop.apache.org/common/docs/current/hdfs-default.html" target="_blank" rel="noopener">http://hadoop.apache.org/common/docs/current/hdfs-default.html</a></p>
<p>   <a href="http://hadoop.apache.org/common/docs/current/mapred-default.html" target="_blank" rel="noopener">http://hadoop.apache.org/common/docs/current/mapred-default.html</a></p>
<p>​     这里是浏览hadoop当前版本号的默认配置文件，其他版本号，要另外去官网找。其中第一个方法找到默认的配置是最好的，因为每个属性都有说明，可以直接使用。另外，core-site.xml是全局配置,hdfs-site.xml和mapred-site.xml分别是hdfs和mapred的局部配置。</p>
<p>2       常用的端口配置2.1  HDFS端口</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
<th>默认</th>
<th>配置文件</th>
<th>例子值</th>
</tr>
</thead>
<tbody>
<tr>
<td>fs.default.name namenode</td>
<td>namenode RPC交互端口</td>
<td>8020</td>
<td>core-site.xml</td>
<td>hdfs://master:8020/</td>
</tr>
<tr>
<td>dfs.http.address</td>
<td>NameNode web管理端口</td>
<td>50070</td>
<td>hdfs- site.xml</td>
<td>0.0.0.0:50070</td>
</tr>
<tr>
<td>dfs.datanode.address</td>
<td>datanode　控制端口</td>
<td>50010</td>
<td>hdfs -site.xml</td>
<td>0.0.0.0:50010</td>
</tr>
<tr>
<td>dfs.datanode.ipc.address</td>
<td>datanode的RPC服务器地址和端口</td>
<td>50020</td>
<td>hdfs-site.xml</td>
<td>0.0.0.0:50020</td>
</tr>
<tr>
<td>dfs.datanode.http.address</td>
<td>datanode的HTTP服务器和端口</td>
<td>50075</td>
<td>hdfs-site.xml</td>
<td>0.0.0.0:50075</td>
</tr>
</tbody>
</table>
<p>2.2  MR端口</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
<th>默认</th>
<th>配置文件</th>
<th>例子值</th>
</tr>
</thead>
<tbody>
<tr>
<td>mapred.job.tracker</td>
<td>job-tracker交互端口</td>
<td>8021</td>
<td>mapred-site.xml</td>
<td>hdfs://master:8021/</td>
</tr>
<tr>
<td>job</td>
<td>tracker的web管理端口</td>
<td>50030</td>
<td>mapred-site.xml</td>
<td>0.0.0.0:50030</td>
</tr>
<tr>
<td>mapred.task.tracker.http.address</td>
<td>task-tracker的HTTP端口</td>
<td>50060</td>
<td>mapred-site.xml</td>
<td>0.0.0.0:50060</td>
</tr>
</tbody>
</table>
<p>2.3  其它端口</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
<th>默认</th>
<th>配置文件</th>
<th>例子值</th>
</tr>
</thead>
<tbody>
<tr>
<td>dfs.secondary.http.address</td>
<td>secondary NameNode web管理端口</td>
<td>50090</td>
<td>hdfs-site.xml</td>
<td>0.0.0.0:50090</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>3       三个缺省配置参考文件说明3.1  core-default.html</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>参数名</th>
<th>参数值</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>hadoop.tmp.dir</td>
<td>/tmp/hadoop-${user.name}</td>
<td>临时目录设定</td>
</tr>
<tr>
<td>2</td>
<td>hadoop.native.lib</td>
<td>true</td>
<td>使用本地hadoop库标识。</td>
</tr>
<tr>
<td>3</td>
<td>hadoop.http.filter.initializers</td>
<td></td>
<td>http服务器过滤链设置</td>
</tr>
<tr>
<td>4</td>
<td>hadoop.security.group.mapping</td>
<td>org.apache.hadoop.security.ShellBasedUnixGroupsMapping</td>
<td>组内用户的列表的类设定</td>
</tr>
<tr>
<td>5</td>
<td>hadoop.security.authorization</td>
<td>false</td>
<td>服务端认证开启</td>
</tr>
<tr>
<td>6</td>
<td>hadoop.security.authentication</td>
<td>simple</td>
<td>无认证或认证设置</td>
</tr>
<tr>
<td>7</td>
<td>hadoop.security.token.service.use_ip</td>
<td>true</td>
<td>是否开启使用IP地址作为连接的开关</td>
</tr>
<tr>
<td>8</td>
<td>hadoop.logfile.size</td>
<td>10000000</td>
<td>日志文件最大为10M</td>
</tr>
<tr>
<td>9</td>
<td>hadoop.logfile.count</td>
<td>10</td>
<td>日志文件数量为10个</td>
</tr>
<tr>
<td>10</td>
<td>io.file.buffer.size</td>
<td>4096</td>
<td>流文件的缓冲区为4K</td>
</tr>
<tr>
<td>11</td>
<td>io.bytes.per.checksum</td>
<td>512</td>
<td>校验位数为512字节</td>
</tr>
<tr>
<td>12</td>
<td>io.skip.checksum.errors</td>
<td>false</td>
<td>校验出错后是抛出异常还是略过标识。True则略过。</td>
</tr>
<tr>
<td>13</td>
<td>io.compression.codecs</td>
<td>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec</td>
<td>压缩和解压的方式设置</td>
</tr>
<tr>
<td>14</td>
<td>io.serializations</td>
<td>org.apache.hadoop.io.serializer.WritableSerialization</td>
<td>序例化和反序列化的类设定</td>
</tr>
<tr>
<td>15</td>
<td>fs.default.name</td>
<td>file:///</td>
<td>缺省的文件URI标识设定。</td>
</tr>
<tr>
<td>16</td>
<td>fs.trash.interval</td>
<td>0</td>
<td>文件废弃标识设定，0为禁止此功能</td>
</tr>
<tr>
<td>17</td>
<td>fs.file.impl</td>
<td>org.apache.hadoop.fs.LocalFileSystem</td>
<td>本地文件操作类设置</td>
</tr>
<tr>
<td>18</td>
<td>fs.hdfs.impl</td>
<td>org.apache.hadoop.hdfs.DistributedFileSystem</td>
<td>HDFS文件操作类设置</td>
</tr>
<tr>
<td>19</td>
<td>fs.s3.impl</td>
<td>org.apache.hadoop.fs.s3.S3FileSystem</td>
<td>S3文件操作类设置</td>
</tr>
<tr>
<td>20</td>
<td>fs.s3n.impl</td>
<td>org.apache.hadoop.fs.s3native.NativeS3FileSystem</td>
<td>S3文件本地操作类设置</td>
</tr>
<tr>
<td>21</td>
<td>fs.kfs.impl</td>
<td>org.apache.hadoop.fs.kfs.KosmosFileSystem</td>
<td>KFS文件操作类设置.</td>
</tr>
<tr>
<td>22</td>
<td>fs.hftp.impl</td>
<td>org.apache.hadoop.hdfs.HftpFileSystem</td>
<td>HTTP方式操作文件设置</td>
</tr>
<tr>
<td>23</td>
<td>fs.hsftp.impl</td>
<td>org.apache.hadoop.hdfs.HsftpFileSystem</td>
<td>HTTPS方式操作文件设置</td>
</tr>
<tr>
<td>24</td>
<td>fs.webhdfs.impl</td>
<td>org.apache.hadoop.hdfs.web.WebHdfsFileSystem</td>
<td>WEB方式操作文件类设置</td>
</tr>
<tr>
<td>25</td>
<td>fs.ftp.impl</td>
<td>org.apache.hadoop.fs.ftp.FTPFileSystem</td>
<td>FTP文件操作类设置</td>
</tr>
<tr>
<td>26</td>
<td>fs.ramfs.impl</td>
<td>org.apache.hadoop.fs.InMemoryFileSystem</td>
<td>内存文件操作类设置</td>
</tr>
<tr>
<td>27</td>
<td>fs.har.impl</td>
<td>org.apache.hadoop.fs.HarFileSystem</td>
<td>压缩文件操作类设置.</td>
</tr>
<tr>
<td>28</td>
<td>fs.har.impl.disable.cache</td>
<td>true</td>
<td>是否缓存har文件的标识设定</td>
</tr>
<tr>
<td>29</td>
<td>fs.checkpoint.dir</td>
<td>${hadoop.tmp.dir}/dfs/namesecondary</td>
<td>备份名称节点的存放目前录设置</td>
</tr>
<tr>
<td>30</td>
<td>fs.checkpoint.edits.dir</td>
<td>${fs.checkpoint.dir}</td>
<td>备份名称节点日志文件的存放目前录设置</td>
</tr>
<tr>
<td>31</td>
<td>fs.checkpoint.period</td>
<td>3600</td>
<td>动态检查的间隔时间设置</td>
</tr>
<tr>
<td>32</td>
<td>fs.checkpoint.size</td>
<td>67108864</td>
<td>日志文件大小为64M</td>
</tr>
<tr>
<td>33</td>
<td>fs.s3.block.size</td>
<td>67108864</td>
<td>写S3文件系统的块的大小为64M</td>
</tr>
<tr>
<td>34</td>
<td>fs.s3.buffer.dir</td>
<td>${hadoop.tmp.dir}/s3</td>
<td>S3文件数据的本地存放目录</td>
</tr>
<tr>
<td>35</td>
<td>fs.s3.maxRetries</td>
<td>4</td>
<td>S3文件数据的偿试读写次数</td>
</tr>
<tr>
<td>36</td>
<td>fs.s3.sleepTimeSeconds</td>
<td>10</td>
<td>S3文件偿试的间隔</td>
</tr>
<tr>
<td>37</td>
<td>local.cache.size</td>
<td>10737418240</td>
<td>缓存大小设置为10GB</td>
</tr>
<tr>
<td>38</td>
<td>io.seqfile.compress.blocksize</td>
<td>1000000</td>
<td>压缩流式文件中的最小块数为100万</td>
</tr>
<tr>
<td>39</td>
<td>io.seqfile.lazydecompress</td>
<td>true</td>
<td>块是否需要压缩标识设定</td>
</tr>
<tr>
<td>40</td>
<td>io.seqfile.sorter.recordlimit</td>
<td>1000000</td>
<td>内存中排序记录块类最小为100万</td>
</tr>
<tr>
<td>41</td>
<td>io.mapfile.bloom.size</td>
<td>1048576</td>
<td>BloomMapFiler过滤量为1M</td>
</tr>
<tr>
<td>42</td>
<td>io.mapfile.bloom.error.rate</td>
<td>0.005</td>
<td></td>
</tr>
<tr>
<td>43</td>
<td>hadoop.util.hash.type</td>
<td>murmur</td>
<td>缺少hash方法为murmur</td>
</tr>
<tr>
<td>44</td>
<td>ipc.client.idlethreshold</td>
<td>4000</td>
<td>连接数据最小阀值为4000</td>
</tr>
<tr>
<td>45</td>
<td>ipc.client.kill.max</td>
<td>10</td>
<td>一个客户端连接数最大值为10</td>
</tr>
<tr>
<td>46</td>
<td>ipc.client.connection.maxidletime</td>
<td>10000</td>
<td>断开与服务器连接的时间最大为10秒</td>
</tr>
<tr>
<td>47</td>
<td>ipc.client.connect.max.retries</td>
<td>10</td>
<td>建立与服务器连接的重试次数为10次</td>
</tr>
<tr>
<td>48</td>
<td>ipc.server.listen.queue.size</td>
<td>128</td>
<td>接收客户连接的监听队例的长度为128</td>
</tr>
<tr>
<td>49</td>
<td>ipc.server.tcpnodelay</td>
<td>false</td>
<td>开启或关闭服务器端TCP连接算法</td>
</tr>
<tr>
<td>50</td>
<td>ipc.client.tcpnodelay</td>
<td>false</td>
<td>开启或关闭客户端TCP连接算法</td>
</tr>
<tr>
<td>51</td>
<td>webinterface.private.actions</td>
<td>false</td>
<td>Web交互的行为设定</td>
</tr>
<tr>
<td>52</td>
<td>hadoop.rpc.socket.factory.class.default</td>
<td>org.apache.hadoop.net.StandardSocketFactory</td>
<td>缺省的socket工厂类设置</td>
</tr>
<tr>
<td>53</td>
<td>hadoop.rpc.socket.factory.class.ClientProtocol</td>
<td></td>
<td>与dfs连接时的缺省socket工厂类</td>
</tr>
<tr>
<td>54</td>
<td>hadoop.socks.server</td>
<td></td>
<td>服务端的工厂类缺省设置为SocksSocketFactory.</td>
</tr>
<tr>
<td>55</td>
<td>topology.node.switch.mapping.impl</td>
<td>org.apache.hadoop.net.ScriptBasedMapping</td>
<td></td>
</tr>
<tr>
<td>56</td>
<td>topology.script.file.name</td>
<td></td>
<td></td>
</tr>
<tr>
<td>57</td>
<td>topology.script.number.args</td>
<td>100</td>
<td>参数数量最多为100</td>
</tr>
<tr>
<td>58</td>
<td>hadoop.security.uid.cache.secs</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>3.2  hdfs-default.html</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>参数名</th>
<th>参数值</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>dfs.namenode.logging.level</td>
<td>info</td>
<td>输出日志类型</td>
</tr>
<tr>
<td>2</td>
<td>dfs.secondary.http.address</td>
<td>0.0.0.0:50090</td>
<td>备份名称节点的http协议访问地址与端口</td>
</tr>
<tr>
<td>3</td>
<td>dfs.datanode.address</td>
<td>0.0.0.0:50010</td>
<td>数据节点的TCP管理服务地址和端口</td>
</tr>
<tr>
<td>4</td>
<td>dfs.datanode.http.address</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/HDFS HA的一些补充/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/HDFS HA的一些补充/" itemprop="url">Linux命令进阶</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T10:12:52+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h1 id="HDFS的基本结构"><a href="#HDFS的基本结构" class="headerlink" title="HDFS的基本结构"></a>HDFS的基本结构</h1><p><img src="https://img-blog.csdn.net/20180523163634141?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI0MDczNzA3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p>
<p>如上图所示，HDFS基本结构分NameNode、SecondaryNameNode、DataNode这几个。</p>
<p>NameNode：是Master节点，有点类似Linux里的根目录。管理数据块映射；处理客户端的读写请求；配置副本策略；管理HDFS的名称空间；</p>
<p>SecondaryNameNode：保存着NameNode的部分信息（不是全部信息NameNode宕掉之后恢复数据用），是NameNode的冷备份；合并fsimage和edits然后再发给namenode。（防止edits过大的一种解决方案）</p>
<p>DataNode：负责存储client发来的数据块block；执行数据块的读写操作。是NameNode的小弟。</p>
<p>热备份：b是a的热备份，如果a坏掉。那么b马上运行代替a的工作。</p>
<p>冷备份：b是a的冷备份，如果a坏掉。那么b不能马上代替a工作。但是b上存储a的一些信息，减少a坏掉之后的损失。</p>
<p>fsimage:元数据镜像文件（文件系统的目录树。）</p>
<p>edits：元数据的操作日志（针对文件系统做的修改操作记录）</p>
<p>namenode内存中存储的是=fsimage+edits。</p>
<h1 id="NameNode详解"><a href="#NameNode详解" class="headerlink" title="NameNode详解"></a>NameNode详解</h1><p>作用：</p>
<p>Namenode起一个统领的作用，用户通过namenode来实现对其他数据的访问和操作，类似于root根目录的感觉。</p>
<p>Namenode包含：目录与数据块之间的关系（靠fsimage和edits来实现），数据块和节点之间的关系</p>
<p>fsimage文件与edits文件是Namenode结点上的核心文件。</p>
<p>Namenode中仅仅存储目录树信息，而关于BLOCK的位置信息则是从各个Datanode上传到Namenode上的。</p>
<p>Namenode的目录树信息就是物理的存储在fsimage这个文件中的，当Namenode启动的时候会首先读取fsimage这个文件，将目录树信息装载到内存中。</p>
<p>而edits存储的是日志信息，在Namenode启动后所有对目录结构的增加，删除，修改等操作都会记录到edits文件中，并不会同步的记录在fsimage中。</p>
<p>而当Namenode结点关闭的时候，也不会将fsimage与edits文件进行合并，这个合并的过程实际上是发生在Namenode启动的过程中。</p>
<p>也就是说，当Namenode启动的时候，首先装载fsimage文件，然后在应用edits文件，最后还会将最新的目录树信息更新到新的fsimage文件中，然后启用新的edits文件。</p>
<p>整个流程是没有问题的，但是有个小瑕疵，就是如果Namenode在启动后发生的改变过多，会导致edits文件变得非常大，大得程度与Namenode的更新频率有关系。</p>
<p>那么在下一次Namenode启动的过程中，读取了fsimage文件后，会应用这个无比大的edits文件，导致启动时间变长，并且不可控，可能需要启动几个小时也说不定。</p>
<p>Namenode的edits文件过大的问题，也就是SecondeNamenode要解决的主要问题。</p>
<p>SecondNamenode会按照一定规则被唤醒，然后进行fsimage文件与edits文件的合并，防止edits文件过大，导致Namenode启动时间过长。</p>
<h1 id="DataNode详解"><a href="#DataNode详解" class="headerlink" title="DataNode详解"></a>DataNode详解</h1><p>DataNode在HDFS中真正存储数据。</p>
<p>首先解释块（block）的概念：</p>
<ol>
<li>DataNode在存储数据的时候是按照block为单位读写数据的。block是hdfs读写数据的基本单位。</li>
<li>假设文件大小是100GB，从字节位置0开始，每128MB字节划分为一个block，依此类推，可以划分出很多的block。每个block就是128MB大小。</li>
<li>block本质上是一个 逻辑概念，意味着block里面不会真正的存储数据，只是划分文件的。</li>
<li>block里也会存副本，副本优点是安全，缺点是占空间</li>
</ol>
<p>SecondaryNode</p>
<p>执行过程：从NameNode上 下载元数据信息（fsimage,edits），然后把二者合并，生成新的fsimage，在本地保存，并将其推送到NameNode，同时重置NameNode的edits.</p>
<p>工作原理（转自“大牛笔记”的博客，由于实现是清晰，受益很大，在此不做改动）</p>
<p><img src="https://img-blog.csdn.net/20180523163703307?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI0MDczNzA3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p>
<p>有一个文件FileA，100M大小。Client将FileA写入到HDFS上。</p>
<p>HDFS按默认配置。</p>
<p>HDFS分布在三个机架上Rack1，Rack2，Rack3。</p>
<p>a. Client将FileA按64M分块。分成两块，block1和Block2;</p>
<p>b. Client向nameNode发送写数据请求，如图蓝色虚线①——&gt;。</p>
<p>c. NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线②———&gt;。</p>
<p>​    Block1: host2,host1,host3</p>
<p>​    Block2: host7,host8,host4</p>
<p>​    原理：</p>
<p>​        NameNode具有RackAware机架感知功能，这个可以配置。</p>
<p>​        若client为DataNode节点，那存储block时，规则为：副本1，同client的节点上；副本2，不同机架节点上；副本3，同第二个副本机架的另一个节点上；其他副本随机挑选。</p>
<p>​        若client不为DataNode节点，那存储block时，规则为：副本1，随机选择一个节点上；副本2，不同副本1，机架上；副本3，同副本2相同的另一个节点上；其他副本随机挑选。</p>
<p>d. client向DataNode发送block1；发送过程是以流式写入。</p>
<p>​    流式写入过程，</p>
<p>​        1&gt;将64M的block1按64k的package划分;</p>
<p>​        2&gt;然后将第一个package发送给host2;</p>
<p>​        3&gt;host2接收完后，将第一个package发送给host1，同时client想host2发送第二个package；</p>
<p>​        4&gt;host1接收完第一个package后，发送给host3，同时接收host2发来的第二个package。</p>
<p>​        5&gt;以此类推，如图红线实线所示，直到将block1发送完毕。</p>
<p>​        6&gt;host2,host1,host3向NameNode，host2向Client发送通知，说“消息发送完了”。如图粉红颜色实线所示。</p>
<p>​        7&gt;client收到host2发来的消息后，向namenode发送消息，说我写完了。这样就真完成了。如图黄色粗实线</p>
<p>​        8&gt;发送完block1后，再向host7，host8，host4发送block2，如图蓝色实线所示。</p>
<p>​        9&gt;发送完block2后，host7,host8,host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。</p>
<p>​        10&gt;client向NameNode发送消息，说我写完了，如图黄色粗实线。。。这样就完毕了。</p>
<p>分析，通过写过程，我们可以了解到：</p>
<p>​    ①写1T文件，我们需要3T的存储，3T的网络流量贷款。</p>
<p>​    ②在执行读或写的过程中，NameNode和DataNode通过HeartBeat进行保存通信，确定DataNode活着。如果发现DataNode死掉了，就将死掉的DataNode上的数据，放到其他节点去。读取时，要读其他节点去。</p>
<p>​    ③挂掉一个节点，没关系，还有其他节点可以备份；甚至，挂掉某一个机架，也没关系；其他机架上，也有备份。</p>
<h1 id="读操作："><a href="#读操作：" class="headerlink" title="读操作："></a>读操作：</h1><p>读操作就简单一些了，如图所示，client要从datanode上，读取FileA。而FileA由block1和block2组成。 </p>
<p>那么，读操作流程为：</p>
<p>a. client向namenode发送读请求。</p>
<p>b. namenode查看Metadata信息，返回fileA的block的位置。</p>
<p>​    block1:host2,host1,host3</p>
<p>​    block2:host7,host8,host4</p>
<p>c. block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取；</p>
<p>上面例子中，client位于机架外，那么如果client位于机架内某个DataNode上，例如,client是host6。那么读取的时候，遵循的规律是：</p>
<p>优选读取本机架上的数据。</p>
<p>运算和存储在同一个服务器中，每一个服务器都可以是本地服务器</p>
<p>补充</p>
<p>元数据</p>
<p>元数据被定义为：描述数据的数据，对数据及信息资源的描述性信息。（类似于Linux中的i节点）</p>
<p>以 “blk_”开头的文件就是 存储数据的block。这里的命名是有规律的，除了block文件外，还有后 缀是“meta”的文件 ，这是block的源数据文件，存放一些元数据信息。</p>
<p>数据复制</p>
<p>NameNode做出关于块复制的所有决定。它周期性地从集群中的每个DataNode接收到一个心跳和一个阻塞报告。收到心跳意味着DataNode正常运行。Blockreport包含DataNode上所有块的列表。</p>
<h2 id="此博客为转发博客"><a href="#此博客为转发博客" class="headerlink" title="此博客为转发博客"></a><font color="red" size="3">此博客为转发博客</font></h2>
          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/MapReduce架构设计/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="skygzx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="skygzx">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/MapReduce架构设计/" itemprop="url">MapReduce架构设计</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T10:08:49+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

	 

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <a id="more"></a>
<h2 id="1-MapReduce-分布式计算框架"><a href="#1-MapReduce-分布式计算框架" class="headerlink" title="1.MapReduce 分布式计算框架"></a><strong>1.MapReduce 分布式计算框架</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">企业开发不用jiav代码，很复杂，很累赘，mr job基于磁盘运算，速度太慢</span><br><span class="line">Map：映射（元素的个数)</span><br><span class="line">hadoop001：</span><br><span class="line">x --》(x,1)  key,value 键值对</span><br><span class="line">y --》(y,1)</span><br><span class="line">z --》(z,1)</span><br><span class="line">x --》(x,1)</span><br><span class="line"></span><br><span class="line">hadoop002：</span><br><span class="line">x --》(x,1)</span><br><span class="line">z --》(z,1)</span><br><span class="line"></span><br><span class="line">Reduce: 归约</span><br><span class="line">x,2</span><br><span class="line">y,1</span><br><span class="line">z,1</span><br></pre></td></tr></table></figure>
<p>**</p>
<h2 id="2-MapReduce架构（重要）"><a href="#2-MapReduce架构（重要）" class="headerlink" title="2.MapReduce架构（重要）"></a>2.MapReduce架构（重要）</h2><p><strong>
</strong>当面试的时候问到，MapReduce 架构设计、Yarn架构设计、Yarn的工作流程、MapReduce job 提交到 Yarn的工作流程 （面试题为同一题），其实都是同一个问题。**<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">on Yarn 运行在Yarn上</span><br><span class="line">容器：container（Yarn的资源的抽象概念）</span><br><span class="line">运行在 Yarn nodemanager节点机器上，是一个虚拟的概念，将内存和cpu（vcore)封装成最小的单元，运行我们计算的任务task。</span><br></pre></td></tr></table></figure></p>
<p><img src="https://img-blog.csdnimg.cn/20190311181914828.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTg1MTQy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vcore 虚拟core </span><br><span class="line"></span><br><span class="line">YARN中目前的CPU被划分成虚拟CPU（CPU virtual Core），</span><br><span class="line">这里的虚拟CPU是YARN自己引入的概念，</span><br><span class="line">初衷是，考虑到不同节点的CPU性能可能不同，</span><br><span class="line">每个CPU具有的计算能力也是不一样的，</span><br><span class="line">比如某个物理CPU的计算能力可能是另外一个物理CPU的2倍，</span><br><span class="line">这时候，你可以通过为第一个物理CPU多配置几个虚拟CPU弥补这种差异。</span><br><span class="line">用户提交作业时，可以指定每个任务需要的虚拟CPU个数。</span><br><span class="line"></span><br><span class="line">物理core</span><br><span class="line">vcore: 虚拟内核 </span><br><span class="line"></span><br><span class="line">4core--》(生产1:2 默认，1:1) </span><br><span class="line">处理并行度提高</span><br></pre></td></tr></table></figure>
<h2 id="3-task-运行计算任务在-container"><a href="#3-task-运行计算任务在-container" class="headerlink" title="3.task 运行计算任务在 container"></a><strong>3.task 运行计算任务在 container</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Yarn：</span><br><span class="line">job也叫 app也叫 application 也叫作业 </span><br><span class="line">ResourceManager：资源作业管理者</span><br><span class="line">它有两个属下（Applications Manager 作业管理</span><br><span class="line">			 Resource Scheduler 资源调度）</span><br><span class="line">NodeManager：节点管理者</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190311182936818.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTg1MTQy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">	 1.用户向yarn提交应用程序（job），其中包括application Master程序，启动application Master命令等</span><br><span class="line">	 2.RM为该job分配了一个容器，并于对应的NM通信，要求它在这个容器中启动job的MR application Master程序</span><br><span class="line">	 3.启动程序之后，applocation Master首先向ApplicationsManager注册，用户就可以直接在web界面上查看job的整个运行状态和日志</span><br><span class="line">	 4.applicationMaster向Resource Scheduler采用轮询的方式通过RPC协议去申请和领取资源列表</span><br><span class="line">	 5.一旦applicationMaster申请到资源后，便与对应的NM节点通信，要求启动任务</span><br><span class="line">	 6.NM为任务task设置好运行环境（环境变量，jar），将任务的启动命令写在一个脚本文件中，并通过脚本文件【启动任务】</span><br><span class="line">	 7.各个task通过RPC协议向applicationMaster汇报自己的状态和进度，以让applicationMaster随时掌握各个任务的运行状态，从而可以在任务运行时重新启动任务，则web界面可以实时查看job当前运行状态。</span><br><span class="line">	 8.job运行完成后，applicationMaster向RM注销自己并关闭自己</span><br><span class="line"></span><br><span class="line">一共分为两个阶段：</span><br><span class="line"></span><br><span class="line">&gt; 启动applicationMaster</span><br><span class="line">&gt; 由applicationMaster创建job，为它上去资源，并监控它的整个运行过程，知道运行完成</span><br></pre></td></tr></table></figure>
<h2 id="4-shuffle-洗牌"><a href="#4-shuffle-洗牌" class="headerlink" title="4.shuffle 洗牌"></a><strong>4.shuffle 洗牌</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">map--&gt; shufle--&gt; reduce</span><br><span class="line"></span><br><span class="line">map task默认设置为3个，reduce task默认设为1个，所以结果只有一个文件</span><br></pre></td></tr></table></figure>
<p>祥细看一下博客：<a href="http://blog.itpub.net/30089851/viewspace-2095837/" target="_blank" rel="noopener">http://blog.itpub.net/30089851/viewspace-2095837/</a><br><img src="https://img-blog.csdnimg.cn/20190311184400892.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTg1MTQy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><strong>5.常用命令</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop002 bin]$ mapred --help</span><br><span class="line">Usage: mapred [--config confdir] COMMAND</span><br><span class="line">       where COMMAND is one of:</span><br><span class="line">  pipes                run a Pipes job</span><br><span class="line">  job                  manipulate MapReduce jobs</span><br><span class="line">  queue                get information regarding JobQueues</span><br><span class="line">  classpath            prints the class path needed for running</span><br><span class="line">                       mapreduce subcommands</span><br><span class="line">  historyserver        run job history servers as a standalone daemon</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  archive-logs         combine aggregated logs into hadoop archives</span><br><span class="line">  hsadmin              job history server admin interface</span><br><span class="line"></span><br><span class="line">Most commands print help when invoked w/o parameters.</span><br><span class="line">[hadoop@hadoop002 bin]$ mapred job </span><br><span class="line">Usage: CLI &lt;command&gt; &lt;args&gt;</span><br><span class="line">        [-submit &lt;job-file&gt;]</span><br><span class="line">        [-status &lt;job-id&gt;]</span><br><span class="line">        [-counter &lt;job-id&gt; &lt;group-name&gt; &lt;counter-name&gt;]</span><br><span class="line">        [-kill &lt;job-id&gt;]</span><br><span class="line">        [-set-priority &lt;job-id&gt; &lt;priority&gt;]. Valid values for priorities are: VERY_HIGH HIGH NORMAL LOW VERY_LOW</span><br><span class="line">        [-events &lt;job-id&gt; &lt;from-event-#&gt; &lt;#-of-events&gt;]</span><br><span class="line">        [-history [all] &lt;jobHistoryFile|jobId&gt; [-outfile &lt;file&gt;] [-format &lt;human|json&gt;]]</span><br><span class="line">        [-list [all]]</span><br><span class="line">        [-list-active-trackers]</span><br><span class="line">        [-list-blacklisted-trackers]</span><br><span class="line">        [-list-attempt-ids &lt;job-id&gt; &lt;task-type&gt; &lt;task-state&gt;]. Valid values for &lt;task-type&gt; are MAP REDUCE. Valid values for &lt;task-state&gt; are running, completed</span><br><span class="line">        [-kill-task &lt;task-attempt-id&gt;]</span><br><span class="line">        [-fail-task &lt;task-attempt-id&gt;]</span><br><span class="line">        [-logs &lt;job-id&gt; &lt;task-attempt-id&gt;]</span><br><span class="line"></span><br><span class="line">Generic options supported are</span><br><span class="line">-conf &lt;configuration file&gt;     specify an application configuration file</span><br><span class="line">-D &lt;property=value&gt;            use value for given property</span><br><span class="line">-fs &lt;local|namenode:port&gt;      specify a namenode</span><br><span class="line">-jt &lt;local|resourcemanager:port&gt;    specify a ResourceManager</span><br><span class="line">-files &lt;comma separated list of files&gt;    specify comma separated files to be copied to the map reduce cluster</span><br><span class="line">-libjars &lt;comma separated list of jars&gt;    specify comma separated jar files to include in the classpath.</span><br><span class="line">-archives &lt;comma separated list of archives&gt;    specify comma separated archives to be unarchived on the compute machines.</span><br><span class="line"></span><br><span class="line">The general command line syntax is</span><br><span class="line">bin/hadoop command [genericOptions] [commandOptions]</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop002 bin]$ mapred job -list </span><br><span class="line">19/02/23 21:39:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">19/02/23 21:39:35 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">Total jobs:1</span><br><span class="line">                  JobId      State           StartTime      UserName           Queue      Priority       UsedContainers  RsvdContainers       UsedMem         RsvdMem         NeededMem         AM info</span><br><span class="line"> job_1550323870337_1633       PREP       1550928758524        hadoop     root.hadoop        NORMAL                    0               0            0M              0M                0M      http://hadoop002:8088/proxy/application_1550323870337_1633/</span><br><span class="line">[hadoop@hadoop002 bin]$ mapred job -kill job_1550323870337_1633</span><br><span class="line">19/02/23 21:39:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">19/02/23 21:39:48 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032</span><br><span class="line">19/02/23 21:39:49 INFO impl.YarnClientImpl: Killed application application_1550323870337_1633</span><br><span class="line">Killed job job_1550323870337_1633</span><br><span class="line">[hadoop@hadoop002 bin]$ </span><br><span class="line">[hadoop@hadoop002 bin]$</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

	<div>
      
	</div>

    


    

    

    <div>
    
   </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="skygzx">
            
              <p class="site-author-name" itemprop="name">skygzx</p>
              <p class="site-description motion-element" itemprop="description">记录skygzx的学习历程</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">41</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">32</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友链
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://blog.itpub.net/30089851/" title="hackeruncle" target="_blank">hackeruncle</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://gengzongyuan.github.io/" title="大树" target="_blank">大树</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://blog.csdn.net/tch918" title="在路上" target="_blank">在路上</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://my.oschina.net/u/4005872" title="wuwang" target="_blank">wuwang</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fab fa-angellist"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">skygzx</span>

  
</div>




 <!--<div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>-->



  <span class="post-meta-divider">|</span>



  <!--<div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>-->


<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>





        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
</html>

